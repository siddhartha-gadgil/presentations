<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Automating Mathematics?</title>

	<meta name="description" content="Kaapi with Kuriosity lecture">
	<meta name="author" content="Siddhartha Gadgil">

	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

	<meta name="viewport"
		content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css" id="theme">

	<!-- Code syntax highlighting -->
	<link rel="stylesheet" href="lib/css/zenburn.css">
	<link rel="stylesheet" href="kwk.css">

	<link rel="icon" href="IIScLogo.jpg">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>

	<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
</head>

<body>

	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<section class="slides">
			<section data-transition="slide">
				<h2> Automating Mathematics? </h2>
				<h4>Siddhartha Gadgil</h4>
				<p>Department of Mathematics</p>
				<p>Indian Institute of Science</p>
				<p>Bangalore</p>
				<p><a href="http://math.iisc.ac.in/~gadgil/">http://math.iisc.ac.in/~gadgil/</a></p>
				<p><a href="https://siddhartha-gadgil.github.io/automating-mathematics/"
						target="_blank">https://siddhartha-gadgil.github.io/automating-mathematics/</a></p>


			</section>

			<section data-transition="zoom-in fade-out">
				<ul>
					<li>
						Can computers acquire <strong>all the major capabilities</strong> used by mathematicians and the
						mathematics community in the <strong>discovery</strong> and <strong>proof</strong> of
						mathematical results and concepts?
					</li>
					<li class="fragment">When? <strong>How?</strong></li>
					<li class="fragment">Computers are already used in several ways.</li>
					<li class="fragment">Capabilities in other cognitive domains that suggests they can do much more.</li>
					<li class="fragment">Automated theorem proving is closely related to <strong>computer verification of
							proofs</strong>.</li>
				</ul>
			</section>

			<section data-transition="fade-out">
				<h4>A concrete prediction</h4>
				<ul>
					<li class="fragment">
						Open bet by Christian Szegedy, Google Research.
					</li>
					<li class="fragment">
						By the year 2029:
					</li>
				</ul>
				<blockquote class="fragment">
					"A diverse set of 100 graduate text books are automatically formalized/verified in a popular proof assistant (eg Lean). 10% of problems from a preselected 100 open human conjectures is proved completely autonomously."
				</blockquote>
			</section>

			<section data-transition="zoom-in concave-out" data-background-image="campus.jpg">
				<h1>Ingredients for  Automation</h1>
			</section>

			<section data-transition="convex" data-background-color="#002b36">
				<h4> Universal deducer? </h4>
				<ul>
					<li class="fragment"> A <strong>universal deducer</strong> is a program which, given a
						mathematical statement, either proves it is true or proves it is false.</li>
					<li class="fragment"> By results of Church, G&ouml;del, Turing, such a program is impossible. </li>
					<li class="fragment"> We can seek to build ever more powerful systems that (help in) finding (and verifying) ever more powerful proofs. </li>
					<li class="fragment">This will involve advances of many different kinds in combination.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#002b36">
				<h4>Algorithms</h4>
				<ul>
					<li class="fragment">Numerical computation.</li>
					<li class="fragment"><strong>Enumeration:</strong> a large number of problems of the same form.</li>
					<li class="fragment">Symbolic and computational algebra.</li>
					<li class="fragment"><strong>Compact</strong> enumeration.</li>
					<li class="fragment"><strong>Exact</strong> real number arithmetic.</li>
					<li class="fragment">Linear programming.</li>
					<li class="fragment">Decidability of <strong>real semi-algebraic geometry</strong>.</li>
					<li class="fragment">Many algorithms for specific mathematical questions based on mathematical theorems.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#002b36">
				<h4>Deduction Engines</h4>
				<ul>
					<li class="fragment"><strong>SAT solvers</strong> can solve logical problems with finitely many Boolean variables.</li>
					<li class="fragment">Many finite problems can be reduced to <strong>SAT</strong>.</li>
					<li class="fragment"><strong>SMT solvers</strong> extend SAT solvers with various algorithms.</li>
					<li class="fragment"><strong>Resolution Theorem Provers</strong> can in principle solve any problem in first-order logic, which encodes all of mathematics.</li>
					<li class="fragment">In practice, all these have difficulty handling mathematics <em>in the large</em>.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#002b36">
				<h4>Interactive Theorem Provers</h4>
				<ul>
					<li class="fragment">In <em>Interactive Theorem Provers</em>, proofs are
						obtained by human-machine
						collaboration.</li>
					<li class="fragment">The computer both finds (parts of) proofs and verifies
						<strong>correctness</strong>.</li>
					<li class="fragment">The ease of proving in such systems depends on how <strong>concise</strong>
						and <strong>composable</strong> proofs are and
						the strength of its <strong>automation</strong>.</li>
					<li class="fragment">The power and ease of use also depends on the <strong>library</strong> &ndash; the results that are already in the system.</li>
					<li class="fragment">The system thus accumulates <strong>knowledge</strong> and ways to use it effectively.</li>
				</ul>
			</section>
			<section data-transition="convex" data-background-color="#002b36">
				<h4>Artificial Intelligence</h4>
				<ul>
					<li class="fragment">Manage tasks for which we depend on experience, tacit knowledge.</li>
					<li class="fragment">Work with limited or unstructured data.</li>
					<li class="fragment">Learn and use a composable representation of words, images etc.</li>
					<li class="fragment">Share learning between tasks.</li>
					<li class="fragment">Handle long range dependencies.</li>
					<li class="fragment">Work with a small number of task-specific examples.</li>
					<li class="fragment"><strong>But:</strong> will give some nonsensical answers.</li>
				</ul>
			</section>



			<section data-transition="zoom-in convex-out" data-background="Closepacking.svg"
				data-background-color="#b5533c" data-state="dimbg">
				<h1>Computer Proofs</h1>
				<h2>in</h2>
				<h1>Mathematics</h1>
				<h1>&nbsp;</h1>
				<span class="attribution">
					<a href="https://commons.wikimedia.org/wiki/File:Closepacking.svg">Cdang Derivative work:
						Muskid</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a>, via
					Wikimedia Commons</span>
			</section>


			<section data-transition="convex" data-background-color="#b5533c">
				<h4>Some computer-assisted proofs</h4>
				<ul>
					<li class="fragment"><strong>Four-colour problem:</strong> Any map can be coloured with at most $4$
						colours.</li>
					<li class="fragment"><strong>Kepler Conjecture:</strong> The most efficient way to pack spheres is
						the hexagonal close packing.</li>
					<li class="fragment"><strong>Boolean Pythagorean triples problem:</strong> Is it possible to colour
						the
						positive integers either red or blue, so that if three integers $a$, $b$, $c$,
						satisfy $a^{2}+b^{2}=c^{2}$, they are not all the same colour?</li>
					<li class="fragment"><strong>Smale conjecture</strong> for hyperbolic $3$-manifolds.</li>
				</ul>
			</section>


			<section data-transition="convex" data-background-color="#b5533c">
				<h4> Robbins conjecture </h4>
				<ul>
					<li class="fragment"> <strong>Robbins conjecture</strong> was a conjectural characterization of
						<em>Boolean algebras</em> in
						terms of
						associativity and commutativity of $\vee$ and the Robbins equation
						$\neg(\neg(a\vee b)\vee \neg(a \vee \neg b)) = a$.</li>
					<li class="fragment"> This was conjectured in the 1930s, and finally proved in 1996 using the
						automated theorem prover <strong>EQP</strong>.</li>
					<li class="fragment"> So far, this seems to be the only major success of <strong>fully
							autonomous</strong> deductive theorem provers.
					</li>
			</section>

			<section data-transition="zoom" data-background="code.png">
				<h1>SAT Solvers</h1>
			</section>

			<section data-transition="convex" data-background-color="teal">
				<h4>The $N-$Queens problem</h4>
				<ul>
					<li class="fragment">
						The $N-$queens puzzle is the problem of placing $N$ chess queens on an $N\times N$ chessboard
						so that no two queens threaten each other.
					</li>
					<li class="fragment">
						Thus, a solution requires that no two queens share the same row, column, or diagonal.
					</li>
					<li class="fragment"> We formulate this as a so called <strong>Boolean satisfiability (SAT) problem.</strong>
					</li>
					<li class="fragment"> A <strong>SAT solver</strong> solves SAT problems.</li>
					<li class="fragment">A very large class of problems can be formulated as SAT problems.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="teal">
				<h4>$N$-Queens as SAT</h4>
				<ul>
					<li class="fragment">We associate to each square a <em>boolean</em> variable $Q_{i,j}$ which is <em>true</em> iff the
						square is occupied.</li>
					<li class="fragment">We construct logical formulas for the constraints of the $N-$queens puzzle from the
						$Q_{i,j}$'s using operators $\neg$ (<em>not</em>), $\vee$(<em>or</em>) and $\wedge$(<em>and</em>).</li>
					<li class="fragment">For example, the $i$th row has a queen is the formula $Q_{i,1}\vee Q_{i,2}\vee\dots\vee Q_{i,n}$
					</li>
					<li class="fragment">Similarly, pairs of queens not threatening each other gives formulas such as $\neg Q_{1, 1}\vee
						\neg Q_{2, 2}$.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="teal">
				<h4>SAT Problems</h4>
				<ul>
					<li class="fragment">We are given finitely many <em>boolean</em> variables $P$, $Q$, ... and finitely many
						<em>constraints</em> on them.
					</li>
					<li class="fragment">
						Constraints are logical statements built from the variables using logical operators such as
						$\neg$ (<em>not</em>), $\vee$(<em>or</em>), $\wedge$(<em>and</em>),
						$\Rightarrow$(<em>implies</em>) and $\Leftrightarrow$ (<em>equivalent</em>).
					</li>
					<li class="fragment">
						The <strong>SAT</strong> (<em>boolean satisfiability</em>) problem asks whether we can assign
						truth values to these (i.e., declare each of $P$, $Q$ , ... to be $true$ or $false$) so that all
						the constraints are satisfied.
					</li>
				</ul>
			</section>
			<section data-transition="convex" data-background-color="teal">
				<h4>SAT and $P\overset{?}=NP$</h4>
				<ul>
					<li class="fragment">
						Given a solution to a SAT problem, it is easy to see that it satisfies all the constraints.
					</li>
					<li class="fragment">
						However, <em>finding</em> a solution may be hard.
					</li>
					<li class="fragment">
						Algorithmic problems that can be <strong>solved</strong> in polynomial time form the class
						<strong>$P$</strong> (polynomial).
					</li>
					<li class="fragment">
						Algorithmic problems whose solution, if it exists, can be <strong>checked</strong> in polynomial
						time form the class <strong>$NP$</strong> (non-deterministic polynomial).
					</li>
					<li class="fragment">A fundamental question is whether $P = NP$.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="teal">
				<h4>Cook-Levine theorem</h4>
				<ul>
					<li class="fragment">The <em>Cook-Levine theorem</em> from the early 1970s showed that if SAT can be solved in
						polynomial time
						then so can every problem in $NP$.</li>
					<li class="fragment">
						There are a large class of problems that are known to be $NP$, making $P=NP$ a very important
						question.
					</li>
					<li class="fragment">
						In practice, computer scientists have focussed efforts on making practically fast SAT solvers,
						which are
						used to solve (components of) many different problems by mapping them to SAT.
					</li>
				</ul>
			</section>
			<section data-transition="convex" data-background-color="teal">
				<h4>Resolution and the DPLL algorithm</h4>
				<ul>
					<li class="fragment">
						The formulation of $N$-Queens above was as a collection of <em>clauses</em>, i.e., in <em>CNF</em>.
					</li>
					<li class="fragment">Any SAT problem can be formulated in CNF.</li>
					<li class="fragment">Davis and Putnam showed that a deduction rule called <em>Resolution</em> is <em>refutation complete</em> for SAT, and indeed for First-Order Logic.
					</li>
					<li class="fragment">
						The DPLL algorithm refines the algorithm of Davis-Putnam for SAT.
					</li>
					<li class="fragment">
						Together with Robinson's <em>unification</em>, the Davis-Putnam work gives <em>Resolution Theorem Provers</em>, which can deduce any provable theorem.
					</li>
					
				</ul>
			</section>
			<section data-background-iframe="Q8.html" data-background-color="teal"></section>
			<section data-background-iframe="Q3.html" data-background-color="white"></section>
			<section data-transition="convex" data-background-color="teal">
				<h4>SAT Solver-Prover in Lean 4</h4>
				<ul>
					<li class="fragment">
						In <strong>Lean 4</strong>, 
						we can have a program with output one of
						<ul>
							<li class="fragment">
								a solution together with a proof that this is a solution, or
							</li>
							<li class="fragment">
								a proof that there is no solution.
							</li>
						</ul>
					</li>
					<li class="fragment">
						Furthermore, the compiler verifies that the program terminates for any valid input, and has
						correct output of one of the above two forms.
					</li>
					<li class="fragment">I implemented this in a program <strong>SATurn</strong>.</li>
					<li class="fragment">This was the first time in my experience that such a complex program ran correctly straight away. </li>
				</ul>
			</section>
			<section data-background="lean4-saturn.png" data-background-color="white"></section>

			<section>
				<h1>SMT Solvers</h1>
			</section>
			<section>
				<h4>Z3 Demo: Sudoku</h4>
				<img src="sudoku.png" alt="Sudoku puzzle" height="500">
			</section>

			<section>
				<h4>Euclidean Geometry via SMT?</h4>
				<ul>
					<li class="fragment">
						In the 1950s, Tarski proved that whether a collection of polynomial equations and inequations has solutions that are real numbers is decidable. 
					</li>
					<li class="fragment">Statements in Euclidean geometry can be translated to such problems.</li>
					<li class="fragment"> Tarski’s algorithm has been greatly improved, and algorithms of a more algebraic nature have also been developed, improved and implemented. 
					</li>
					<li class="fragment">
						However, I could not find any examples of using SMT solvers for such problems.
					</li>
					
				</ul>
			</section>

			<section>
				<h4>Pappus hexagon theorem</h4>
				<p><strong>Theorem:</strong> $P$, $Q$ and $R$ are collinear.</p>
				<img src="Pappus.png" alt="Pappus configuration" height="370">
				
			</section>

			<section>
				<ul>
					<li>
						Points with coordinates $(x_1, y_1)$, $(x_2, y_2)$ and $(x_3, y_3)$, which we assume to be distinct, are <em>collinear</em> if and only if $(y_2 - y_1)(x_3 - x_1) = (y_3 - y_1)(x_2 - x_1).$
					</li>
					<li class="fragment">As a warm up, we show that for $P= (x, y)$, $P$, $O=(0, 0)$ and $-P$ are collinear.</li>
					<li class="fragment"> To do this, we seek $x$ and $y$ so that $P$, $O$ and $-P$ are <em>not</em> collinear, and check for solutions.
					</li>
					<li class="fragment">
						Indeed Z3 and CVC4 concluded instantly that there is no solution, i.e., the points are collinear.
					</li>					
					
				</ul>
			</section>

			<section>
				<ul>
					<img src="Pappus.png" alt="Pappus configuration" height="200">
					<li class="fragment">We scale and rotate to obtain nice coordinates</li>
					<li class="fragment">
						We can take $a=(1, 0)$, $b= (1 + u, 0)$, $c = (1 + u + v, 0)$ with $u, v > 0$. 
					</li>
					<li class="fragment">Let $A = (x_A, y_A)$, then $B = (x_A(1+ U), y_A(1 + U))$ and $C = (x_A(1+ U + V), y_A(1 + U + V))$ with $U, V, y_A > 0$.</li>
				</ul>
			</section>

			<section>
				<ul>
					<img src="Pappus.png" alt="Pappus configuration" height="200">
					<li class="fragment">We let $P=(P_x, P_y)$, $Q=(Q_x, Q_y)$ and $R= (R_x, R_y)$, giving $12$ variables in all. </li>
					<li class="fragment">We get $6$ equations for collinearity, e.g. of $A$, $P$ and $b$. </li>
					<li class="fragment">
						We also have various positivity inequations.
					</li>
					<li class="fragment">We negate the equation for $P$, $Q$ and $R$ being collinear and ask if there is a solution.</li>
				</ul>
			</section>


			<section>
				<ul>
					<li>
						Unfortunately when I ran Z3 with this system it did not give a result.
					</li>
					<li class="fragment">I blogged about this formulation and result.</li>
					<li class="fragment"> A couple of days later Anand Rao Tadipatri emailed me that he had got Z3 to prove Menelaus’s Theorem along similar lines.
					</li>
					<li class="fragment">
						Strangely, I could not replicate his result.
					</li>					
					<li class="fragment">
						It turns out that Z3 <strong>can solver both theorems</strong> if only asked for an answer, but neither if asked for a <strong>proof</strong>.
					</li>
				</ul>
			</section>



			<section data-transition="zoom-in concave-out" data-background-image="campus.jpg">
				<h1 style="color:#fffdd0">Computer Verification for Mathematics</h1>
			</section>

			<section data-transition="concave" data-background-color="#002b36">
				<h4>Interactive Theorem Provers</h4>
				<ul>
					<li class="fragment"><em>Interactive Theorem Provers</em> are software systems where proofs are
						obtained by human-machine
						collaboration.</li>
					<li class="fragment">The computer both finds (parts of) proofs and verifies
						<strong>correctness</strong>.</li>
					<li class="fragment">The ease of proving in such systems depends on how <strong>concise</strong>
						and <strong>composable</strong> proofs are and
						the strength of its <strong>elaborator</strong> and <strong>tactics</strong>.</li>
					<li class="fragment">The former depends on <strong>foundations</strong> and the latter is essentially
						<strong>automated
							theorem proving</strong>.</li>
				</ul>
			</section>

			<section data-transition="concave" data-background-color="#002b36">
				<h4>Who guards the guards?</h4>
				<ul>
					<li class="fragment">
						A computer verified proof is only as trustworthy as the system that verified the proof.
					</li>
					<li class="fragment">
						Following the <em>de Bruijn</em> principle, proofs are <em>verified</em> by a small <em>trusted
							kernel</em>, which can be thoroughly checked.
					</li>
					<li class="fragment">
						For example, the <em>lean theorem prover</em> has three (small) proof checkers written in three
						languages.
					</li>
				</ul>

			</section>

			<section data-transition="concave" data-background-color="#002b36">
				<ul>
					<li class="fragment">The <strong>Feit-Thompson</strong> theorem has been formalized in the system
						<strong>Coq</strong> by Georges Gonthier and others.</li>
					<li class="fragment">The <strong>lean mathematical library</strong> has formalizations of a lot of undergraduate
						mathematics and many advanced results.</li>
					<li class="fragment">These not only show that formalization is feasible, but can form data for both <strong>machine
							learning</strong> and advanced <strong>semantic searches</strong> and other tooling.</li>
				</ul>
			</section>


			<section data-transition="zoom-in convex-out" data-background-image="hills.png">
				<h1>&nbsp;</h1>
				<h1 style="color:#fffdd0">Formal methods</h1>
				<h2>Mathematical proofs elsewhere</h2>
				<p>&nbsp;</p>
			</section>

			<section data-transition="convex" data-background="#b5533c">
				<h4>Formal methods</h4>
				<ul>

					<li class="fragment">We <strong>specify</strong> (describe) software, hardware etc. in precise
						mathematical terms.
					</li>
					<li class="fragment">We give <strong>mathematical proofs</strong> of correct behavior, which are
						<strong>computer
							verified</strong>.</li>
					<li class="fragment">This gives a much greater certainty of correctness.</li>
					<li class="fragment">However, proofs are much harder than tests.</li>
					<li class="fragment">Formal proofs use interactive theorem provers; with better provers we can
						prove more often.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<h4>Do we need <em>completely correct always</em>?</h4>

				<table class="box">
					<tr class="fragment">
						<td> <img src="Intel_Pentium_A80501.jpg" alt="Intel_Pentium_A80501" height="100px" /> </td>
						<td>Pentium FDIV Bug</td>
						<td> <span class="fragment"> Fixing an error is very costly </span c></td>
					</tr>
					<tr class="fragment">
						<td> <img src="Therac25_Interface.png" alt="Therac25_Interface" /> </td>
						<td>Therac 25 radiation machine</td>
						<td> <span class="fragment"> Safety critical</span> </td>
					</tr>
					<tr class="fragment">
						<td> <img src="whatsapp.png" alt="WhatsApp" /> </td>
						<td>WhatsApp Pegasus attack</td>
						<td> <span class="fragment"> A bug is a <em>vulnerability</em></span> </td>
					</tr>
				</table>

			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<h4>Some users of formal methods</h4>

				<table class="box">
					<tr class="fragment">
						<td> <img src="intel-core.jpeg" alt="intel-core" height="100px" /> </td>
						<td>Intel Chips</td>
						<td> <span class="fragment"> Fixing an error is very costly </span c></td>
					</tr>
					<tr class="fragment">
						<td> <img src="paris-metro.jpg" alt="Paris Metro" /> </td>
						<td>Paris driverless metro</td>
						<td> <span class="fragment"> Safety critical</span> </td>
					</tr>
					<tr class="fragment">
						<td> <img src="dotty.png" alt="scala dotty" height="100px" /> </td>
						<td>Scala dotty compiler</td>
						<td> <span class="fragment"> A bug is a vulnerability</span> </td>
					</tr>
				</table>

			</section>

			<section data-transition="zoom-in concave-out" data-background="alpha-zero.jpg">
				<h1>&nbsp;</h1>
				<h1 style="color:#fffdd0">Computers</h1>
				<h1 style="color:#fffdd0">and Games</h1>
			</section>

			<section data-background-color="#002b36" data-transition="concave">
				<h4><q>Programming a Computer for Playing Chess</q></h4>
				<ul>
					<li class="fragment"> Playing Chess can be based on
						<ul>
							<li class="fragment">judging the <strong>value</strong> of a fixed players position.</li>
							<li class="fragment">a <strong>policy</strong>: sequences of moves to consider.
							</li>
						</ul>
					</li>
					<li class="fragment"> We compute (and use) the value at the end of sequences moves we consider.
					</li>
					<li class="fragment"> We recursively decide the best moves
						by <strong>minimax</strong> &mdash; alternately maximizing and minimizing.
					</li>
					<li class="fragment">We refine using various heuristics, such as <strong>quiescence search</strong>
						and
						<strong>$\alpha-\beta$ pruning</strong>.
					</li>
					<li class="fragment"><em>Openings</em> give a <strong>policy</strong>, as do
						<em>endgame tables</em>.</li>
				</ul>
			</section>
			<section data-background-color="#002b36" data-transition="concave">
				<h4>Kasparov vs Deep Blue</h4>
				<ul>
					<li class="fragment">In 1997, a computer <strong>Deep Blue</strong> defeated the Chess world champion Gary Kasparov.
					</li>
					<li class="fragment"> Deep Blue was based on extending the above methods to elaborate <strong>(rule
						based)</strong> values and policies (chess theory), and improved <strong>heuristics</strong>.</li>
					<li class="fragment">However, Deep Blues was very limited in certain <strong>capabilities</strong>.</li>
					<li class="fragment"> The value and policy functions of Kasparov were far better, but compensated
						for by Deep Blue being able to consider far more move sequences.</li>
				</ul>

			</section>
			<section data-background-color="#002b36" data-transition="concave">
				<h4>AlphaGo vs Lee Sedol</h4>
				<ul>
					<li class="fragment"> In the chinese game Go, the number of legal moves is much larger, so
						<em>trying everything</em> means we cannot look many moves ahead.</li>
					<li class="fragment"> More importantly, it is very hard to describe a good value function (we use
						<strong>tacit knowledge</strong>).</li>
					<li class="fragment"> This makes it far harder for computers.</li>
					<li class="fragment"> Yet, in March 2016, a Go playing system AlphaGo defeated 18-time world
						champion Lee Sedol.</li>
					<li class="fragment"> In January 2017, AlphaGo defeated the world number one Ke Jie
						comprehensively.
					</li>
				</ul>
			</section>
			<section data-background-color="#002b36" data-transition="concave">
				<h4>AlphaGo and Learning</h4>
				<ul>
					<li class="fragment"> The policy and value functions of AlphaGo are <em>deep neural networks</em>
						that were
						<em>trained</em>.</li>
					<li class="fragment"> The policy network was initially trained by learning to predict the next move
						from
						games
						of expert players (<strong>behaviour cloning</strong>).</li>
					<li class="fragment"> The value network was trained by AlphaGo playing against versions of itself.
					</li>
					<li class="fragment"> AlphaGo considered fewer sequences of moves than Deep Blue.</li>
					<li class="fragment"> AlphaGo came up with unexpected moves.</li>
				</ul>
			</section>


			<section data-background-color="#002b36" data-transition="concave">
				<h4>AlphaGo Zero and Alpha Zero</h4>
				<ul>
					<li class="fragment">AlphaGo was succeeded (and defeated) by <em>AlphaGo Zero</em>, which learnt
						purely by
						self play.</li>
					<li class="fragment">Its successor, <em>AlphaZero</em>, could master a variety of similar games
						starting with
						just the rules.</li>
					<li class="fragment">AlphaZero took just 4 hours to become the strongest chess player on the planet
						(beating a traditional chess program, Stockfish).</li>
					<li class="fragment">AlphaZero &ldquo;had a dynamic, open style&rdquo;, and &ldquo;prioritizes
						piece
						activity over material, preferring positions that looked risky and aggressive.&rdquo;</li>
				</ul>
			</section>

			<section data-transition="zoom" data-background="sea.jpg">
				<h1>Artificial Intelligence elsewhere</h1>
			</section>

			<section data-transition="concave" data-background-color="#b5533c">
				<h4>Word Embeddings</h4>
				<ul>
					<li class="fragment">
						To give words a <em>structure</em> and capture relations, words are <em>embedded</em> as points
						in space.</li>
					<li class="fragment">To do this, (in <strong>Word2Vec</strong>) we set up the problem of predicting a word given its
						neighbours.</li>
					<li class="fragment">We look for solutions of this problem that involve mapping words into space, and predicting from
						neighbours using the points.
					</li>
					<li class="fragment"> Analogies such as <em>Paris</em> is to <em>France</em> as <em>Madrid</em> is to
						<em>Spain</em> are captured by <em>vector operations</em>.</li>
				</ul>
			</section>

			<section data-transition="concave" data-background-color="#b5533c" S>
				<h4>Generative Adversarial Network</h4>
				<ul>
					<li class="fragment">These consist of a pair of networks, contesting with
						each other.</li>
					<li class="fragment"> One network generates candidates (generative) and
						the other evaluates them (discriminative).</li>
					<li class="fragment">For example the discriminative network tries to
						distinguish between real images and synthetic ones
						generated by the generative network.</li>
				</ul>
			</section>


			<section data-transition="concave" data-background-color="#b5533c">
				<h4><q>Attention is all you need</q></h4>
				<ul>
					<li class="fragment">The meaning of a word depends on the context, i.e., other words surrounding it.</li>
					<li class="fragment">In the <em>transformer architecture</em>, this is captured by <strong>learning</strong>
						to which other words to pay attention for determining the next representation.
					</li>
					<li class="fragment">The encoding of words includes position vectors, defined by using harmonics.</li>
					<li class="fragment">This has lead to revolutionary improvements, including forming the basis for <strong>GPT
							3</strong>.</li>
					<li class="fragment">Attention networks are used in <strong>AlphaFold 2</strong>.</li>
				</ul>
			</section>


			<section data-transition="zoom" data-background="code.png">
				<h1>Artificial Intelligence</h1>
				<h4>for</h4>
				<h1> Mathematical Proofs?</h1>
			</section>

			<section data-transition="convex" data-background-color="teal">
				<ul>
					<li class="fragment">
						First-order logic theorem provers (based on Resolution, SAT solvers) are very powerful at deducing consequences of a small set of premises.
					</li>
					<li class="fragment">The main limitation is <em>premise selection</em> &ndash; choosing the already proved results from which to deduce.</li>
					<li class="fragment">In <strong>DeepMath</strong>, deep learning is used effectively for this task.</li>
				</ul>
			</section>

			<section data-background-image="minerva.png"></section>
			
			<section>
				<img src="HyperTree.png" alt="" height="100%">
			</section>

			<section data-transition="concave" data-background-color="#b5533c" S>
				<h4>LLMs/Foundation models</h4>
				<ul>
					<li class="fragment">These are based on the <em>Transformer</em> architecture.</li>
					<li class="fragment"> They are pre-trained on a huge dataset and may be fine-tuned on a more specific one.</li>
					<li class="fragment"> For a specific task, often a small prompt (typically some examples) is enough.</li>
					<img src="imagen.png" alt="" class="fragment"></img>
				</ul>
			</section>

	</div>
	</div>

	<script src="js/reveal.js"></script>
	

	<script>

		// Full list of configuration options available at:
		// https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			history: true,
			center: true,

			transition: 'slide', // none/fade/slide/concave/concave/zoom


			math: {
				mathjax: '../MathJax/MathJax.js',
				//				mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
				// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
				config: 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
			},

			// Optional reveal.js plugins
			dependencies: [
				{ src: 'lib/js/classList.js', condition: function () { return !document.body.classList; } },
				{ src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				// { src: '../highlight/highlight.pack.js', async: true, condition: function () { return !!document.querySelector('pre code'); }, callback: function () { hljs.initHighlightingOnLoad(); } },
				{ src: 'plugin/highlight/highlight.js', async: true },
				{ src: 'plugin/zoom-js/zoom.js', async: true },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/math/math.js', async: true }
			]
		});

//			Reveal.addEventListener( 'slidechanged', function( event ) {
//				MathJax.Hub.Rerender();
//			} );

	</script>

</body>

</html>