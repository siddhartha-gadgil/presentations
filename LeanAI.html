<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Lean and AI</title>

	<meta name="description" content="Chalmers lecture">
	<meta name="author" content="Siddhartha Gadgil">

	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

	<meta name="viewport"
		content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css" id="theme">

	<!-- Code syntax highlighting -->
	<link rel="stylesheet" href="lib/css/zenburn.css">
	<link rel="stylesheet" href="pg.css">

	<link rel="icon" href="IIScLogo.jpg">

	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reset.css" />
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reveal.css" />
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/theme/black.css" id="theme" />

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>

	<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
</head>

<body>

	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<section class="slides">
			<section data-transition="slide">
				<h3> Autoformalization and Friends: </h3>
				<h3> Interactive Theorem Provers </h3>
				<h5>and</h4>
					<h3>Artificial Intelligence</h3>
					<p>Chalmers, Aug 2024</p>
					<h3>Siddhartha Gadgil</h3>
					<p>Indian Institute of Science, Bangalore</p>


			</section>


			<section data-transition="zoom-in fade-out">
				<ul>
					<li>I began my research in <em>low-dimensional topology</em>, doing a Ph.D. at
						<strong>Caltech</strong>
						(advisor: David Gabai).
					</li>
					<li>For the next 10-15 years, I mainly worked in
						low-dimensional topology and related fields such as <em>geometric group theory</em> and
						<em>riemannian geometry</em>.
					</li>
					<li class="fragment">Since about 2014, I have increasingly focussed on Automated Theorem Proving,
						based initially on
						<ul>
							<li>(Homotopy) Type theory and related foundations.</li>
							<li>Implementing these in scala (ProvingGround).</li>
							<li>Dabbling in Agda and Idris.</li>
						</ul>
					</li>
					<li class="fragment">Surprisingly both strands of my career came together in the <em>PolyMath
							adventure.</em></li>
				</ul>
			</section>

			<section data-transition="convex" data-background="#b5533c">
				<h3>The PolyMath 14 participants</h3>
				<ul>
					<li>Tobias Fritz, MPI MIS</li>
					<li> Siddhartha Gadgil, IISc, Bangalore </li>
					<li> Apoorva Khare, IISc, Bangalore</li>
					<li> Pace Nielsen, BYU </li>
					<li> Lior Silberman, UBC </li>
					<li> Terence Tao, UCLA </li>
				</ul>

			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>On Saturday, December 16, 2017, Terrence Tao posted on his blog a question, which Apoorva Khare
						had asked him.</li>
					<blockquote>
						Is there a homogeneous, (conjugacy invariant) length function on the free group on two
						generators?
					</blockquote>
					<li class="fragment">Six days later, this was answered in a collaboration involving several
						mathematicians (and a computer).</li>
					<li class="fragment">We begin with an account of this episode.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>Let $\mathcal{W}$ be the set of finite words in the alphabet $\{\alpha, \beta, \bar\alpha,
						\bar\beta\}$,
						with multiplication given by concatenation and $e$ the empty word.
					</li>
					<li class="fragment">
						<strong>Question:</strong> Is there a non-negative, real-valued function $l$ on $\mathcal{W}$
						such that for $g, h\in\mathcal{W}$,
						<ol>
							<li>$l(e) =0$,</li>
							<li>$l(g\cdot\lambda\bar\lambda\cdot h) = l(g\cdot h) = l(g\cdot\bar\lambda\lambda\cdot h)$,
								for $\lambda=\alpha,\beta$ <strong>($l$ defined on the free group)</strong>,</li>
							<li>$l(g\cdot h)\leq l(g) + l(h)$ <strong>(triangle inequality)</strong>,</li>
							<li>if $l(g) = 0$ then $g\sim e$ <strong>(positivity)</strong>,</li>
							<li>$l(g^n)=nl(g)$, <strong>(homogeneity)</strong>?</li>
						</ol>
					</li>
					<li class="fragment"><em>Pseudo-lengths</em> satisfy 1 &ndash; 3, <em>lengths</em> satisfy 1 &ndash; 4.</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>Over the first 4-5 days after the question was posted,
						<ul>
							<li>there were many (failed, but instructive) attempts to construct such length functions;
							</li>
							<li class="fragment">in particular I focussed on a construction using <em>non-crossing matchings</em>,
								but this was not homogeneous;</li>
							<li class="fragment">the failures of various constructions led to the feeling that
								$l(\alpha\beta\bar\alpha\bar\beta) = 0$ for homogeneous pseudo-lengths, which violates
								positivity.</li>
						</ul>
					</li>
				</ul>
			</section>

			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>Increasingly sharp bounds and methods of combining bounds were found.</li>
					<li>But there was no visible path to proving $l(\alpha\beta\bar\alpha\bar\beta) = 0$.</li>
					<li class="fragment">I searched for bounds using an algorithm to calculate the non-crossing
						matchings length,
						together with interactive use of homogeneity.
					</li>
					<li class="fragment">On Thursday morning, I posted a <strong>computer generated, human readable</strong> proof of a
						bound, obtained by upgrading the algorithms to find <strong>proofs</strong> rather than just
						numbers.</li>
				</ul>
			</section>

			<section data-background-iframe="ch-gross-proof.html"></section>

			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>The computer-generated proof was studied by Pace Nielsen, who extracted the <em>internal
							repetition</em> trick. </li>
					<li class="fragment">This was extended by Pace Nielsen and Tobias Fritz and abstracted by Terence Tao.
					</li>
					<li class="fragment">From this Fritz obtained a key lemma.</li>
					<li class="fragment">Using Probability, Terence Tao completed the proof of a result answering the question.</li>
					<li class="fragment">This work became <strong>PolyMath 14</strong>, and has been published in <em>Algebra & Number
							Theory</em>.</li>
				</ul>
			</section>
			<section data-transition="convex" data-background-color="#b5533c">
				<ul>
					<li>The computer generated proof was obtained by an algorithm using <em>domain specific
							foundations</em>. </li>
					<li class="fragment">An account of the computer proof was published in the <em>Journal of Automated reasoning</em>.
					</li>
					<li class="fragment">In response to the referees comments we replicated the computer proof
						(and also addressed the issue of rounding off errors).</li>
					<li class="fragment">The proofs generation, including the replication, have been rewritten in the <em>Lean Theorem
							Prover</em>, using its dual nature as a programming language and interactive theorem prover.
					</li>
				</ul>
			</section>
			<section>
				<ul>
					<li>From the perspective of a Dependent Type Theory (MLTT/CIC/HoTT) it is natural to seek algorithms
						whose output is a proof.</li>
					<li class="fragment">The generation of the proof was such an algorithm combined with an expert
						guided <em>search</em>.</li>
					<li class="fragment">Such generated proofs are <strong>synthetic data</strong>.</li>
					<li class="fragment">Lifting more symbolic algebra algorithms to give proofs can be used to generate
						such data.</li>
					<li class="fragment">This is related to the approach of AlphaGeometry, work of Lample-Charton, etc.</li>
					<li class="fragment">Integrating programs, proofs and mathematics can be useful.</li>
				</ul>
			</section>
			<section>
				<h4>Lean: programs, proofs, meta-programs</h4>
				<ul>
					<li class="fragment">Lean is a <em>dependently typed</em>, <em>functional</em> language.
					</li>
					<li class="fragment">Lean's <strong>type system</strong> is rich enough to express arbitrary mathematical theorems, making Lean an <em>Interactive Theorem Prover</em>.
					</li>
					<li class="fragment">Lean has a fast runtime, allowing
						<strong>self-hosting</strong>.
					</li>
					<li class="fragment">Using this dual nature, I implemented <strong>SATurn</strong>, a SAT
						<em>solver-prover</em> in Lean</strong>: the output is either a proof of UNSAT or a proved
						solution.</li>
					<li class="fragment">In collaboration with Anand Rao Tadipatri, we formalized Gardam's disproof of
					<strong>Kaplansky's unit conjecture</strong> using computations and proofs.</li>
				</ul>
			</section>

			<section data-transition="zoom-in concave-out" data-background-image="campus.jpg">
				<p><strong class="larger">LeanAide:</strong></p>
				<p><strong class="larger">Autoformalization and Beyond</strong></p>
			</section>

			<section data-background-color="teal">
				<h4>LeanAide: Autoformalization of statements</h4>
				<ul>
					<li class="fragment">Our tool <strong>LeanAide</strong> uses LLMs like GPT-4 to translate
						statements (similar to docstrings) into Lean 4 code.</li>
					<li class="fragment">We do prompt engineering and post-processing.</li>
					<li class="fragment">Lean 4 is written (mostly) in Lean 4, and has convenient functions
						for using its interpreter, greatly facilitating our post-processing.</li>
					<li class="fragment">LeanAide is integrated with the user-interface of Lean 4 via code actions.</li>
				</ul>
			</section>

			<section data-background-video="leanaide-jan24.webm" data-background-video-muted> </section>

			<section data-background-color="teal">
				<h4>LeanAide: Prompting </h4>
				<ul>
					<li class="fragment">Suppose we are given the statement of a theorem.</li>
					<li class="fragment">We find (say) 20 documentation strings in Lean's mathematical library
						<em>Mathlib</em>
						that are closest to the statement (for OpenAI embeddings) and include them in the prompt as
						examples.
					</li>
					<li class="fragment">We query GPT-4 with the prompt for (say) 10
						responses.</li>
				</ul>
			</section>

			<section data-background-color="teal">
				<h4>LeanAide: post-processing </h4>
				<ul>
					<li class="fragment">We discard responses that are not valid Lean code (do not parse or do not
						elaborate).</li>
					<li class="fragment">However, the correct response may be preceded by some text or enclosed in a
						code block (in spite of instructions). So we attempt to parse and elaborate for each group of
						consecutive lines.</li>
					<li class="fragment">We also do some mild autocorrections, mainly for convention issues like <code>Prime</code> versus <code>IsPrime</code>.</li>
					<li class="fragment">We also use <em>majority voting</em>, grouping together responses that can be
						proved equivalent by a search tactic called <code>Aesop</code>.</li>
				</ul>
			</section>


			<section data-background-color="teal">
				<ul>
					<li>If a vector space is $2$-dimensional, then it is finite dimensional.
						<pre><code data-trim data-noescape class="language-json">
								[{"role": "system",
								"content": "You are a coding assistant who translates from natural language to Lean Theorem Prover code following examples. Follow EXACTLY the examples given."},
								{"role": "user",
								"content": "If a vector space has a finite basis, then it is finite-dimensional. "},
								{"role": "assistant",
								"content": "∀ {K : Type u} {V : Type v} [inst : DivisionRing K] [inst_1 :
								AddCommGroup V] [inst_2 : Module K V] {ι : Type w}\n [inst_3 : Finite ι], Basis ι
								K V → FiniteDimensional K V"},
								...
								{"role": "user",
								"content": "If a vector space has dimension ‘2‘ then it is finite dimensional."}]
							  </code></pre>
					</li>

				</ul>
			</section>
			<section data-background-color="teal" class="language-lean">
				<ul>
					<li>Translation to Lean:
						If a vector space is $2$-dimensional, then it is finite dimensional.
						<pre><code data-trim data-noescape>
							theorem: ∀ {K : Type u} {V : Type v} 
							[inst : DivisionRing K] [inst_1 : AddCommGroup V] 
							[inst_2 : Module K V],
								Module.rank K V = 2 → FiniteDimensional K V
							  </code></pre>
					</li>
					<li class="fragment">This was one of our $40$ test <em>silly statements</em> (to avoid
						contamination).</li>
					<li class="fragment">We also had $40$ <em>theorems</em> and $40$ <em>false</em> statements in our
						test set. </li>
					<li class="fragment">On the test set of 120 example problems, we had a success rate of about 85%.
					</li>
				</ul>
				</ul>
			</section>


			<section data-background-color="teal">
				<h4>Better translation?</h4>
				<ul>
					<li class="fragment">However, the success rate of LeanAide was below 50% for the standard
						<em>ProofNet</em>
						dataset.</li>
					<li class="fragment">Generally, failure of translation happened when prompts lacked adequate
						examples.</li>
					<li class="fragment">This could be due to
						<ul>
							<li>
								Selection of prompts not being good enough.
							</li>
							<li class="fragment">
								Not enough prompts among Mathlib docstrings.
							</li>
							<li class="fragment">
								Choice of terminology not matching Mathlib, e.g. <em>condensation points</em>
								versus <em>accumulation points</em>.
							</li>
						</ul>
					</li>
					<li class="fragment">The latter two issues can be (partially) addressed with auxiliary tasks.</li>
				</ul>
			</section>
			<section data-background-color="teal">
				<h4>Informalization</h4>
				<ul>
					<li class="fragment">Informalization is describing a formal theorem, proof or some code in natural
						language.</li>
					<li class="fragment">We informalized all Lean theorems that either occured in more than 3 proofs
						or had docstrings.</li>
					<li class="fragment">To do this, we included in the prompt all the <strong>definitions</strong> in
						the statement of the theorem.
					</li>
					<li class="fragment">This has been shared publicly, and the descriptions seem largely correct
						(standalone tool forthcoming).</li>
					<li class="fragment">These have also been incorporated in autoformalization in LeanAide.</li>
				</ul>
			</section>

			<section data-background-color="teal">
				<h4>Paraphrasing statements</h4>
				<ul>
					<li class="fragment">We use a language model to extract <em>mathematical terms</em> from
						documentation strings and to list their synonyms.</li>
					<li class="fragment">We have built a database with these terms and synonyms.</li>
					<li class="fragment">If an input statement fails to translate, we can try to paraphrase it using the
						synonyms.</li>
					</li>
					<li class="fragment">This has not yet been tested or deployed.</li>
				</ul>
			</section>

			<section data-transition="zoom-in concave-out" data-background-image="hills.png">
				<p><strong class="larger">Iterative Formalization</strong></p>
				<h4>and</h4>
				<p><strong class="larger">Proof Search</strong></p>
			</section>

			<section data-background-color="#002b36">
				<h4>Generative AI and Formal Systems</h4>
				<ul>
					<li class="fragment">
						Generative AI has significant language and reasoning capabilities, including analogical
						reasoning with composition.
					</li>
					<li class="fragment">However, it is often inaccurate.</li>
					<li class="fragment">Using an Interactive Theorem Prover to filter responses and give feedback is promising.
					</li>
					<li class="fragment">Autoformalization of texts overlaps with this.</li>
					<li class="fragment">We are working on such an approach, building on previous work including
						<em>Draft, Sketch and Prove</em>, <em>Baldur: Whole-proof generation and repair...</em> and the
						<em>Naproche project</em>.</li>
				</ul>

			</section>

			<section data-background-color="#002b36">
				<h4>Iterative formalization</h4>
				<pre class="mermaid">

					flowchart LR
					  P[(Problem)] --> reasoning[Reasoning by LLM]
					  reasoning --> pf[(Theorem and Proof)];
					  L[(Literature)] --> pf;
					  ans[(Notes/Answers)] --> ocr[OCR and formatting];
					  ocr --> pf;
					  pf --> |LLM|struct[(Structured JSON text)];
					  struct --> form[Autoformalization];
					  form --> lean[(Lean code)];
					  lean --> elab{Elaborate};
					  elab --> |Success|done((Done));
					  elab --> |Error|error((Fix error));
					  elab --> |Sorries|sorry((Fix Sorry));
					  sorry --> |Gap|P;
					  error --> |Details|pf;
					  error --> |Try again|form;
				  </pre>
				<ul>
					<li>We can start with a problem statement, a theorem in the literature or handwritten notes/answers.
					</li>
					<li>We generate a text, then structured JSON by LLM.</li>
					<li>This is translated to Lean programmatically and elaborated, with errors used to iterate.</li>
				</ul>
			</section>


			<section data-background-color="#002b36">
				<ul>
					<li>Mathematical text largely consists of:
						<ul>
							<li>Context statements: assumptions, let statements</li>
							<li>Definitions (auxiliary constructions).</li>
							<li>Assertions (auxiliary lemmas) with <em>justification</em></li>
						</ul>
					</li>
					<li class="fragment">
						The justification typically involves:
						<ul>
							<li>Results, constructions used (instantiations).</li>
							<li>Proof patterns or analogous proofs.</li>
							<li>Proofs: nested mathematical text.</li>
						</ul>
					</li>
					<li class="fragment">The reader fills in details and makes deductions.</li>
					<li class="fragment">The non-trivial, non-algorithmic, part is mostly the auxiliary lemmas/constructions.</li>
					<li class="fragment">We use LLMs and Lean following this pattern.</li>
				</ul>
			</section>
			<section data-background-color="#002b36">
				<h4>Lean code via Structured Proofs</h4>
				<ul>
					<li class="fragment">
						A language model is used to translate text to a JSON format with detailed instructions, with
						each object having a <code>type</code> field as "definition", "theorem", "assumption",
						"assertion" etc.
					</li>
					<li class="fragment">We translate theorems and assertions into statements including their context
						built from assumptions, lets etc and purge duplicates.</li>
					<li class="fragment">Assertions within a proof become <code>have</code> tactics.</li>
					<li class="fragment">Proofs end with (or consist of) a call to the <code>Aesop</code> search tactic
						with appropriate configuration; including "known results" and <em>fallback to sorry</em>.</li>
				</ul>

			</section>

			<section data-background-color="#002b36">
				<h4>An example</h4>
				<ul>
					<li class="fragment">
						<strong>Theorem:</strong> Let $A$ be a square matrix. Prove that if $A^3 = I$ then $A$ is
						diagonalizable.
					</li>
					<li class="fragment"> <strong>Proof:</strong> (LLM generated) Since $A^3 = I$, $A$ satisfies the
						polynomial equation $p(x) = x^3 - 1$. The roots of $p(x)$ are the cube roots of unity, namely
						$1, \omega, \omega^2$, where $\omega = e^{2\pi i/3}$ is a primitive cube root of unity.
						These roots are distinct, so the minimal polynomial of $A$ must divide $p(x)$ and also have
						distinct roots. Therefore, $A$ is diagonalizable.</li>

				</ul>

			</section>

			<section data-background-color="#002b36">
				<h4>Structured Text</h4>
				<pre><code data-trim data-noescape class="language-json">
					[{"type": "theorem",
					"name": "Diagonalizability of A",
					"hypothesis":
					[{"type": "assume", "statement": "A is a square matrix."},
					{"type": "assume", "statement": "A^3 = I."}],
					"conclusion": "A is diagonalizable."},
					"status": "incomplete proof",
					"proof":
					{"type": "proof",
					"steps": [...]
				}]

				  </code></pre>
				  <ul><li>An informal theorem statement is obtained by combining the hypotheses and the conclusion and translated to Lean.</p></li></ul>


			</section>
			<section data-background-color="#002b36">
				<h4>Structured Text: Proof</h4>
				<pre><code data-trim class="language-json">{"type": "proof",
					"steps":
					[{"type": "assert",
						"deduced_from":
						{"known_results":
						["For any matrix A, if A^k = I, then A is a root of the polynomial x^k - 1."],
						"from_context": ["A^3 = I"]},
						"claim": "A satisfies the polynomial equation $p(x) = x^3 - 1$."},
					{"type": "assert",
						"deduced_from":
						{"known_results":
						["The roots of the polynomial x^3 - 1 are the cube roots of unity."]},
						"claim":
						"The roots of $p(x) = x^3 - 1$ are the cube roots of unity, namely $1, \\omega, \\omega^2$, where $\\omega = e^{2\\pi i/3}$."},
					{"type": "assert",
						"deduced_from":
						{"known_results": ["The cube roots of unity are distinct."]},
						"claim": "The roots $1, \\omega, \\omega^2$ are distinct."},
					{"type": "assert",
						"proof-method":
						"By the definition of the minimal polynomial and properties of the polynomial p(x).",
						"deduced_from":
						{"from_context":
						["A satisfies the polynomial equation $p(x) = x^3 - 1$.",
						"The roots $1, \\omega, \\omega^2$ are distinct."]},
						"claim":
						"The minimal polynomial of A must divide $p(x) = x^3 - 1$ and have distinct roots."},
					{"type": "assert",
						"missing":
						[{"type": "problem",
						"statement":
						"Justify why the minimal polynomial having distinct roots implies A is diagonalizable."}],
						"deduced_from":
						{"known_results":
						["A matrix A is diagonalizable if and only if its minimal polynomial has distinct roots."],
						"from_context":
						["The minimal polynomial of A must divide $p(x) = x^3 - 1$ and have distinct roots."]},
						"claim": "A is diagonalizable."}]}
				  </code></pre>
				  <ul>
					<li>We look for "known statements".</li>
					<li>We also search and/or query an LLM for objects corresponding to "missing".</li>
					
				  </ul>
			</section>
			<section>
				<ul>
					<li>My work has depended on:
						<ul><li>
							<strong>Collaborators:</strong> Anand Rao Tadipatri, Ayush Agrawal, Navin Goyal, Ashvni Narayanan; Anirudh Gupta; the Blue Raven team.
						</li>
						<li class="fragment">
							<strong>Compute/Models:</strong> Microsoft's <em>Accelerating Foundation Model Research</em> program; Google's Research credits; DST-FIST funding.
						</li>
						<li class="fragment">
							My broad hope is to:
							<ul>
								<li>Use AI for tools for formalization.</li>
								<li>Use AI and Lean to help with mathematics.</li>
								<li>By complementing the work of others.</li>
								<li>With a focus on tools and workflows.</li>
							</ul>
						</li>
					</ul>
					</li>
				</ul>
			</section>








	</div>


	<script src="js/reveal.js"></script>

	<script>

		// Full list of configuration options available at:
		// https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			history: true,
			center: true,

			transition: 'slide', // none/fade/slide/concave/concave/zoom


			math: {
				mathjax: '../MathJax/MathJax.js',
				//				mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
				// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
				config: 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
			},


			// Optional reveal.js plugins
			dependencies: [
				{ src: 'lib/js/classList.js', condition: function () { return !document.body.classList; } },
				{ src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				//	{ src: '../highlight/highlight.pack.js', async: true, condition: function () { return !!document.querySelector('pre code'); }, callback: function () { hljs.initHighlightingOnLoad(); } },
				{ src: 'plugin/highlight/highlight.js', async: true },
				{ src: 'plugin/zoom-js/zoom.js', async: true },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/math/math.js', async: true }
			]
		});

		//			Reveal.addEventListener( 'slidechanged', function( event ) {
		//				MathJax.Hub.Rerender();
		//			} );

	</script>
	<script type="module">
		import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
		mermaid.initialize({ startOnLoad: true });
	</script>

</body>

</html>