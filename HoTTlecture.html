<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Homotopy Type theory</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/moon.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<link rel="icon" href="../IIScLogo.jpg">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<section>
 	<section>
	<h1> Homotopy Type Theory </h1>
	 <h3>Siddhartha Gadgil</h3>
	 <p>Department of Mathematics</p>
	 <p>Indian Institute of Science</p>
	 <p>Bangalore</p>
	 <p><a href="https://github.com/siddhartha-gadgil/ProvingGround" target="_blank">https://github.com/siddhartha-gadgil/ProvingGround</a></p>
	 </section>
	<section>
	  <img src="hott-cover-web.png" height="600" />
	  </section>

</section>

<section>
	<section>
		<h3>Foundations of Mathematics</h3>
		 <p>Words and Rules</p>
		 <p>Sets and Predicate Calculus</p>
		 <p>Why we need new foundations</p>
	</section>
	<section>
	  <h3> Formal languages </h3>
	  <ul>
	  <li> Consider the following statements
	    <ol>
	      <li> $\forall (n \in \mathbb{N})\ n < n + 1$ <strong class="fragment"> &nbsp; &nbsp; &nbsp; &nbsp; -- true</strong></li>
		<li> $\exists (n \in \mathbb{N})\ n = n + 1 $<strong class="fragment"> &nbsp; &nbsp; &nbsp; &nbsp; -- false</strong></li>
		<li> $\exists (n \in \mathbb{N})\ n = + + \forall m  $<strong class="fragment"> &nbsp;  -- not well-formed</strong></li>
		<li> $\left\vert\sqrt{-1} + \sqrt[3]{1}\right\vert <1$<strong class="fragment"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; -- not well-defined</strong></li>
	    </ol>
	    </li>
	  <li class="fragment"> A formal language has
	    <ul>
	      <li class="fragment"> A vocabulary,</li>
	      <li class="fragment"> Grammar - rules for forming expressions from simpler ones (starting with the vocabulary).</li>
	      <li class="fragment"> All well-formed expressions are well-defined.</li>
	      <li class="fragment"> Rules are <em>purely syntactic</em>
					<span class="fragment">, i.e., in terms of concatenating words, matching patterns (formed by concatenation), substituting words by other words etc. </span></li>
	      </ul>
	  </ul>
	</section>

	<section>
	  <h3> First-order languages</h3>
	  <ul>
	  <li class="fragment"> A first-order language has vocabulary consisting of
	    <ul>
	      <li class="fragment highlight-current-blue"> Variables - can be taken to be a fixed countable set.</li>
	      <li class="fragment highlight-current-blue"> Constants.</li>
	      <li class="fragment highlight-current-blue"> Functions $f$; a function $f$ has degree $n\in\mathbb{N}$.</li>
	      <li class="fragment highlight-current-blue"> Predicates (relations) $p$ ; a relation has degree $n\in\mathbb{N}$.</li>
	      <li class="fragment highlight-current-blue"> Special symbols $\Rightarrow$, $\iff$, $\wedge$, $\vee$, $\forall$, $\exists$, ... </li>
	      </ul>
	    <li class="fragment"> We form two kinds of expressions from these, <em>terms</em> and <em> formulas </em>.</li>
	    <li class="fragment"> Terms and formulas may depend on values of some variables.</li>
	    <li class="fragment"> Terms represent objects in the <em> Universe</em>. </li>
	    <li class="fragment"> Formulas are either <em>true</em> or <em>false</em>. </li>
	    </ul>
	</section>

	<section>
	  <h3> Terms and Formulas</h3>
	    <ul>
	      <li class="fragment"> Terms are expressions of the forms:
		<ul>
		  <li  class="fragment highlight-current-blue"> A variable $x$.</li>
		  <li class="fragment highlight-current-blue"> A constant $c$.</li>
		  <li class="fragment highlight-current-blue"> $f(t_1, t_2, \dots, t_n)$ with $f$ a function of degree $n$ and $t_1$, $t_2$, ..., $t_n$ terms.</li>
		  </li>
		</ul>
	      <li class="fragment"> Formulas are expressions of the form
		<ul>
		  <li class="fragment highlight-current-blue"> $p(t_1, t_2, \dots, t_n)$ with $p$ a predicate of degree $n$ and $t_1$, $t_2$, ..., $t_n$ terms.</li>
		  <li class="fragment highlight-current-blue"> $P \Rightarrow Q$, $\neg P$, $P\wedge Q$ etc. for formulas $P$ and $Q$.</li>
		  <li class="fragment highlight-current-blue"> $\forall x\ P$ and $\exists x\ P$ for a variable $x$ and a formula $P$.</li>
		</ul>
	      </li>
	    </ul>
	    </section>

	<section>
	  <h3> Deduction and theories </h3>
	  <ul>
	    <li class="fragment"> We can deduce formulas from other formulas using the rules of deduction. </li>
	    <li class="fragment"> The main deduction rule is <em> Modus Ponens</em> : given $P$ and $P\Rightarrow Q$ we deduce $Q$.</li>
	    <li class="fragment"> A <em> theory</em> is a language together with a collection of statements, called <em> axioms</em> in the language.</li>
	    <li class="fragment"> A statement is <em> deducible</em> in a theory if it can be obtained from the axioms by the rules of deduction.</li>
	    <li class="fragment"> A theory is <em> consistent </em> if, for a formula $P$, we cannot deduce both $P$ and $\neg P$.</li>
	    <li class="fragment"> G&ouml;del's <strong>completeness theorem</strong> says that deducible statements in a theory are exactly the <em> true</em> statements, in terms of models of the theory. </li>
	  </ul>
	</section>

	<section>
	  <h3> Set theory </h3>
	  <ul>
	    <li class="fragment"> The language of set theory has:
	      <ul>
		<li> a single constant $\phi$,</li>
		<li> predicates $\in$ and $=$ of degree $2$.</li>
	      </ul>
	      </li>
	    <li class="fragment"> The usual axioms are called ZFC (Zermelo-Fraenkel and the axiom of choice). </li>
	    <li class="fragment"> By G&#246;del's incompleteness theorem, we cannot prove that Set Theory is consistent.</li>
	    <li class="fragment"> However, as G&#246;del's incompleteness theorem applies to any formal system rich enough for usual mathematics, this is not a reason for avoiding any specific formal system.</li>
	  </ul>
	  </section>

	<section>
	  <p>
	    &ldquo; Since the first half of the 20th century mathematics has been presented as a science based on
	    ZFC and ZFC was introduced as a particular theory in Predicate Logic.
	  </p>
	  <p>
	    &ldquo; Therefore someone who wanted to get to the bottom of things in mathematics had a simple
	    road to follow - learn what Predicate Logic is, then learn a particular theory called ZFC, then
	    learn how to translate propositions about a few basic mathematical concepts into formulas of
	    ZFC, and then <span class="fragment highlight-red"> learn to believe, through examples, that the rest of mathematics can be reduced
	    to these few basic concepts</span>.&rdquo;</p>
<div style="text-align:right">Vladimir Voevodsky</div>
	  </section>

		<section>
<embed src="./Mochizuki.pdf" type="application/pdf" width="1000" height="650"> </embed>

		</section>

		<section>
<embed src="Sela.pdf" type="application/pdf" width="100%" height="650"> </embed>

		</section>

		<section>
<embed src="Verjovsky.pdf" type="application/pdf" width="100%" height="650"> </embed>

		</section>

	<section>
	  <h3> Why new foundations? </h3>
	  <ul>
	    <li class="fragment"> Mathematics formalized in ZFC in predicate calculus, even with category theory, is
	      <ul>
		<li>very verbose,</li>
		<li> highly opaque.</li>
		</ul>
	      </li>
	    <li class="fragment"> Formalization of mathematics that is much closer to actual mathematics will
	      <ul>
		<li class="fragment"> reduce wrong mathematics in the literature.</li>
		<li class="fragment"> help computer assisted mathematics.</li>
		<li class="fragment"> facilitate semantic tools for doing mathematics.</li>
		<li class="fragment"> the body of mathematical knowledge will become mostly mathematics, not meta-mathematics.</p>
	      </ul>
	      </li>
	    </ul>
	</section>


	<section>
<p>
<q> &ldquo; The roadblock that prevented generations of interested mathematicians and computer scientists
from solving the problem of computer verification of mathematical reasoning was the
unpreparedness of foundations of mathematics for the requirements of this task.&rdquo;</q></p>
<p>
<q> &ldquo; Formulating mathematical reasoning in a language <span style="color:green">precise enough for a computer to follow</span>
meant using a foundational system of mathematics <span class="fragment highlight-blue"> not as a standard of consistency applied only
to establish a few fundamental theorems, but as a tool that can be employed in everyday
mathematical work.</span> &rdquo;</q></p>


<div style="float:right"> Vladimir Voevodsky</div>

	</section>

</section>

<section>
	<section>
		<h3>Type theories</h3>
		 <p>Syntax with types</p>
		 <p>Types for sets</p>
		 <p> Propositions as Types</p>
	</section>

 	<section>
	  <h3>Terms and Types</h3>
	  <ul>
	    <li class="fragment">In a type theory, every <em>term</em> has a <em> type </em>.</li>
	    <li class="fragment">We denote the term $a$ having type $A$ by $a: A$.</li>
	    <li class="fragment">We can form terms from simpler terms according to <strong>syntactic</strong> term formation rules.</li>
	    <li class="fragment">Term formation rules depend only on the types of the simpler terms.</li>
	    <li class="fragment">We have rules telling us the type of the newly formed term.</li>
	    <li class="fragment">We have <strong>syntactic</strong> <em>type formation rules</em> allowing the formation of new types.</li>
	    <li class="fragment">Terms include both the terms and formulas of first order logic.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Types as Sets</h3>
	  <ul>
	    <li class="fragment">In type theory, types replace sets, with $a : A$ replacing $a \in A$.</li>
			<li class="fragment">However, while sets can be constructed using axioms, types can be constructed only using the (syntactic) type forming rules.</li>
	    <li class="fragment">Nevertheless, type forming rules are sufficiently rich to construct all sets normally encountered in mathematics.</li>
	  </ul>
	</section>


 	<section>
	  <h3>Function types and functions</h3>
	  <ul>
	    <li class="fragment">Given types $A$ and $B$, we can form the type $A \to B$ of functions from $A$ to $B$.</li>
	    <li class="fragment">Given $f : A \to B$, and $a : A$, we can form the term $f(a) : B$.</li>
	    <li class="fragment">We also need rules for forming functions (i.e., terms whose type is a function type).</li>
	  </ul>
	</section>

 	<section>
	  <h3>More Types and Terms</h3>
	  <ul>
	    <li class="fragment">As a consequence of the type and term forming rules of any type theory we consider, we can form some useful types and terms.</li>
	    <li class="fragment">For types $A$, $B$, we can form the product type $A\times B$.</li>
	    <li class="fragment">Given terms $a : A$ and $b : B$, we can form the pair term $(a, b) : A \times B$.</li>
	    <li class="fragment">For types $A$, $B$, we can form the coproduct (disjoint union) type $A\oplus B$, and two inclusion functions $i : A \to A \oplus B$, $j : B \to A \oplus B$ (which can  be applied). </li>
	    <li class="fragment">We have a type $\mathbb{0}$, so that we never have $a : \mathbb{0}$.</li>
	    <li class="fragment">We have a type $\mathbb{1}$, and a unique term $*$ with $* : \mathbb{1}$.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Dependent type theories</h3>
	  <ul>
	    <li class="fragment">In dependent type theories, types are also terms.</li>
	    <li class="fragment">The type of a type is a <em>universe</em>.</li>
	    <li class="fragment">A universe $\mathfrak{U}$ is a type so that if $A : \mathfrak{U}$, $A$ is a type.</li>
	    <li class="fragment">A <em> dependent type</em> is a type (family) that depends on terms $a : A$ of some given type $A$ (more generally several terms).</li>
	    <li class="fragment">Equivalently, a <em>type family</em> is a function (or iterated function) with codomain a universe.</li>
	    <li class="fragment">Type families are analogous to fiber bundles.</li>
	  </ul>
	</section>

 	<section>
	  <h3>$\prod$-types and $\sum$-types</h3>
	  <p style="text-align:left"> Fix a type family $B : A \to \mathfrak{U}$.</p>
	  <ul>
	    <li class="fragment">We can form the type $\prod_{a : A} B(a)$ of <em>dependent functions</em>, i.e., <em> sections </em> of the bundle $B$.</li>
			<li class="fragment"> Dependent functions $f$ generalizes a function $f : A \to B$, with $f(a)$ specified to be in a codomain $B(a)$ depending on $a : A$.
	    <li class="fragment">If $f : \prod_{a : A} B(a)$ and $a : A$, we can form the term $f(a)$ of type $B(a)$.</li>
	    <li class="fragment">We can form the type $\sum_{a : A} B(a)$ of <em>dependent pairs</em>, i.e., the <em> total space</em> of the bundle $B$.</li>
	    <li class="fragment">For $a : A$ and $b : B(a)$, we can form the dependent pair $(a, b) : \sum_{a : A} B(a)$.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Propositions as types</h3>
	  <ul>
	    <li class="fragment">A type $A$ is <em>inhabited</em> if there is a term $a$ with $a : A$.</li>
	    <li class="fragment">By <em> propostion</em> we mean a logical statement that must be true or false.</li>
	    <li class="fragment">We represent propositions by types.</li>
	    <li class="fragment">If a type $A$ is viewed as a proposition, a term $a : A$ is a <em>proof</em> of (or witness to) $A$.
	    <li class="fragment">In particular, a proposition is <strong>true</strong> if and only if the corresponding type is <strong>inhabited</strong>.</li>
	    <li class="fragment">Note that we must be able to form types representing propositions of interest in mathematics by the type formation rules.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Combining propositions</h3>
	  <p class="fragment"> Let $A$ and $B$ be types, regarded as representing propositions.</p>
	  <ul>
	    <li class="fragment"> The proposition $A \Rightarrow B$ is represented by $A \to B$.</li>
	    <li class="fragment"> The propostion $A\wedge B$ is represented by $A \times B$.</li>
	    <li class="fragment"> The proposition $A \vee B$ is represented by $A \oplus B$.</li>
	    <li class="fragment"> The proposition $\neg A$ is represented by $A \to \mathbb{0}$.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Quantifying propositions</h3>
	  <ul>
	    <li class="fragment">A proposition depending on a variable $x : A$ is represented by a type family $P : A \to \mathfrak{U}$. </li>
	    <li class="fragment">The proposition $\forall x\ P(x)$ is represented by $\prod_{x: A} P(x)$.</li>
	    <li class="fragment">The proposition $\exists x\ P(x)$ is represented by $\sum_{x : A} P(x)$.</li>
	  </ul>
	</section>

 	<section>
	  <h3>Inductive types and type families</h3>
	  <ul>
	    <li class="fragment">While we can build types from other types, the above rules do not let us construct types such as $\mathbb{N}$.</li>
	    <li class="fragment">This is achieved using rules to form <em> inductive types</em> and <em>inductive type families</em>.</li>
	    <li class="fragment">Remarkably, we can also form type families corresponding to predicates (i.e., propositions) such as $\leq$ and $=$ as inductive type families.</li>
	  </ul>
	</section>


</section>

<section>
	<section>
		<h3> (Homotopy) Type theory</h3>
		 <p>Terms, Types, Rules</p>
		 <p>Inductive types</p>
		 <p>Propositions as types</p>
		 <p>Proofs by inductions</p>
	</section>
	<section>
	  <h3> Terms, Types, Universes </h3>
	  <ul>
	  <li class="fragment"> <em>Terms </em>, i.e., (first class) mathematical objects, include not just numbers, functions, spaces but also theorems, proofs and definitions.</li>
	  <div class="fragment"><li> Every term has a <em> type </em>, generally unique.</li>
	    <li> We write $a : A$ to denote the term $a$ having type $A$.
	      </div>
	  <div class="fragment">
	    <li> Types are also terms, whose types are <em> universes</em>.
	      <li> A universe is a type whose members are types.</li>
	      </div>
	  </ul>
	  <p class="fragment">
	    <q cite="https://en.wikipedia.org/wiki/First-class_citizen">In programming language design, a first-class citizen (also type, object, entity, or value) in a given programming language is an entity which supports all the operations generally available to other entities. These operations typically include being passed as an argument, returned from a function, and assigned to a variable.</q></p>
	  </section>
	<section>
	  <h3> Rules: construction, equality, type</h3>
	  <ul>
	    <li class="fragment"> We have rules to introduce terms (including types), individually or in groups, into the context.</li>
	    <li class="fragment"> As always, such rules depend on pre-existing terms only through their types.</li>
	    <li class="fragment"> Rules also let us make two kinds of <strong>judgements</strong>:
	      <ul>
		<li> that a term $a$  is of type $A$. </li>
		<li> that two terms are equal <em> by definition </em>.
	      </ul></li>
	    <li class="fragment">  Note that terms can be equal without being so by definition. </li>
	    <li class="fragment"> We will introduce a relation (type family) <em> propositional equality</em> extending definitional equality.</li>
	    </ul>
	</section>

	<section>
	  <h3> A finite type : Booleans</h3>
	  <ul>
	    <li class="fragment"> We can introduce a finite type together with its elements.</li>
	    <li class="fragment"> For instance, we can introduce the <em>Boolean</em> type with two members, <em> true</em> and <em> false</em>.</li>
	    <div class="fragment">
	      <li> In terms of code in the language/proof-assistant <em> Agda</em>,</li>
<pre><code class="haskell">
data Bool : Type where
  true : Bool
  false : Bool

</code></pre>
</div>
	    <li class="fragment"> Note that we do not have rules saying (directly) that each element of $Bool$ is one of $true$ and $false$, or that $true\neq false.$</li>
	</section>

	<section>
	  <h3> Function types, functions and applications </h3>
	  <ul>
	    <li class="fragment"> Given types $A$ and $B$, we can introduce the function type $A \to B$, whose members are functions.</li>
	    <li class="fragment"> Given $f: A \to B$ and $a : A$, we get a term $f(a) : B$.</li>
	    <div class="fragment">
	      <li> We can construct a function $f: A \to B$ by giving an expression of type $B$ in terms of a variable $a : A$ and other terms in the context.</li>
<pre><code class="haskell">
idBool : Bool → Bool -- lambda
idBool x = x

alwaysTrue : Bool → Bool
alwaysTrue x = true
</code></pre>
</div>
	    <li class="fragment"> For specific domains $A$, we have additional rules for constructing functions.</li>
	    </ul>
	</section>

	<section>
	  <h3> Definition by cases </h3>
	  <ul>
	  <li class="fragment"> If the type $A$ is a finite type, we can define a function by enumerating over all members.</li>
<div class="fragment">
<pre><code class="haskell">
not : Bool → Bool -- case defn
not true = false
not false = true

notnot : Bool → Bool -- lambda
notnot x = not(not(x))
</code></pre>
</div>
	  <li class="fragment"> Implicit in being able to make such definitions are statements saying that $true$ and $false$ are distinct and the only members of $Bool$.
	  <li class="fragment"> This is a special instance of <em>recursive</em> definitions.</li>
	  <li class="fragment"> Formally, in homotopy type theory we have rules for introducing a <em> recursion </em> function, which is applied to the definition data to give recursive defintions.
	    </li>
	  </ul>
	</section>
	<section>
	  <h3> Currying functions of several variables</h3>
	  <ul>
	    <li class="fragment"> We do not need additional types for functions of more than one variable.</li>
	    <li class="fragment"> Instead we <em> Curry </em> such a function $(A, B) \to C$, giving an <em> iterated function </em> of type $A \to B \to C := A \to (B \to C)$.</li>
	    <li class="fragment"> Namely, we associate to $g(x, y)$ the function $$x \mapsto (y \mapsto g(x, y)).$$</li>
<div class="fragment">
<pre><code class="haskell">
_&_ : Bool → Bool → Bool --curried function
true & x = x
false & _ = false

</code></pre>
</ul>
	</section>

	<section>
	  <h3> Natural numbers : an inductive type</h3>
	  <ul>
	    <li class="fragment"> Though natural numbers are not finite, they are freely generated by a finite number of constructors.</li>
<div class="fragment">
<pre><code class="haskell">
data ℕ : Type where -- infinite type
  zero : ℕ
  succ : ℕ → ℕ

</code></pre>
</div>
	    <li class="fragment">Such a type is called the inductive type freely generated by the given constructors.</li>
	    <li class="fragment"> Rules giving the allowed types of the constructors are a little subtle.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Recursive definitions </h3>
	  <ul>
	    <li class="fragment"> We can define functions recursively on inductive types, by specifying in all cases.</li>
	    <li class="fragment"> Formally, we can introduce recursion functions and apply them to the definition data. </li>
	    </ul>
<div class="fragment">
<pre><code class="haskell">
even : ℕ → Bool -- recursive definition
even zero = true
even (succ x) = not (even x)

_+_ : ℕ → ℕ → ℕ
zero + y = y
succ x + y = x + (succ y)

</code></pre>
</div>
	</section>

	<section>
	  <h3> Lists : Another Inductive type </h3>
<div class="fragment">
<pre><code class="haskell">
data ℕList : Type where --list type
  [] : ℕList -- empty list
  _::_ : ℕ → ℕList → ℕList -- add number to head of list

mylist : ℕList
mylist = 3 :: (4 :: (2 :: [])) -- the list [3, 4, 2]

</code></pre>
</div>
	</section>

	<section>
	  <h3> Dependent functions and type families </h3>
	  <ul>
	    <li class="fragment"> We generalize functions $f : A \to B$ to <em> dependent functions</em>, so that $f(a)$ has a type $B(a)$, depending in general on $a : A$.</li>
	    <li class="fragment"> More precisely,
	      <ul>
		<li class="fragment"> A <em> type family</em> $B: A \to \mathfrak{U}$ is a function with codomain a universe, so all its values are types. </li>
		<li class="fragment"> Given a type family $B: A \to \mathfrak{U}$, we can construct a corresponding type $\prod_{a : A} B(a)$ of dependent functions.</li>
		<li class="fragment"> When we apply $f : \prod_{a : A} B(a)$ to $a : A$, we obtain $f(a) : B(a)$.</li>
		</ul>
	      </li>
	  <li class="fragment"> Dependent functions are just sections of bundles. </li>
	  <li class="fragment"> Constructions of dependent functions are analogous to those of functions.</li>
	  </ul>
	  </section>

	<section>
	  <h3>Vectors : an inductive type family </h3>
	  <ul>
	    <li class="fragment"> We have a type family associating to each $n : \mathbb{N}$ the type of vectors of length $n$ with entries in $\mathbb{N}$.</li>
	    <li class="fragment"> This is an inductive type family with two constructors.</li>
<div class="fragment">
<pre><code class="haskell">
data Vector : ℕ → Type where -- inductive type family
  [] : Vector 0
  _::_ : {n : ℕ} → ℕ → Vector n → Vector (succ n)
</code></pre>
</div>
	    <li class="fragment"> We can define dependent functions to this type family <em>inductively</em>.</li>
<div class="fragment">
<pre><code class="haskell">
countdown : (n : ℕ) → Vector n -- dependent function
countdown 0 = []
countdown (succ n) = (succ n) :: (countdown n)
</code></pre>
</div>
	    <li class="fragment"> Formally, we can construct an <em>induction function</em> and apply it to the data.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Functions on type families </h3>
	  <ul>
	    <li class="fragment"> We can define (dependent) functions on inductive type families recursively (inductively).</li>
	    <li class="fragment"> However, we must define these simultaneously on all types in the inductive type family.</li>
<div class="fragment">
<pre><code class="haskell">
sum : {n : ℕ} → Vector n → ℕ
sum [] = 0
sum (x :: l) = x + sum l

</code></pre>
</div>
	    <li class="fragment"> Using our foundations, we can also make some practical calculations.</li>
<div class="fragment">
<pre><code class="haskell">
sumToN : ℕ → ℕ -- calculation
sumToN n = sum(countdown n)

</code></pre>
</div>

	  </ul>
	  </section>

	<section>
	  <h3> Propositions from inductive types </h3>
	  <ul>
	    <li class="fragment"> We view propositions as types, with members of the type witnesses (or proofs).</li>
	    <li class="fragment"> Basic propositions can be constructed as inductive types.</li>
<div class="fragment">
<pre><code class="haskell">
data isEven : ℕ → Type where
  0even : isEven 0
  +2even : (n : ℕ) → isEven n → isEven (succ(succ(n)))
</code></pre>
</div>

	    <li class="fragment"> We can prove results using our methods of construction.</li>
<div class="fragment">
<pre><code class="haskell">
4even : isEven 4
4even = +2even _ (+2even _ 0even)
</code></pre>
</div>
	    </ul>
	  </section>

	<section>
	  <ul>
	    <li class="fragment"> For propositions $A$ and $B$ viewed as types, $A \Rightarrow B$ corresponds to $A \to B$.</li>
	    <li class="fragment"> A contradiction corresponds to the type $\mathbb{0}$ (also called $False$) which has no elements.</li>
	    <li class="fragment"> We prove contradictions by inductive definitions which we can see have no cases.</li>
<div class="fragment">
<pre><code class="haskell">
data False : Type where

1odd : isEven 1 → False
1odd ()

3odd : isEven 3 → False
3odd (+2even .1 ())

</code></pre>
</div>
	  </ul>
	  </section>

	<section>
	  <h3> Functions with conditions </h3>
	  <ul>
	    <li class="fragment"> In mathematics (and software), we often define functions subject to the argument satisfying some condition.</li>
	    <li class="fragment"> This can be done very elegantly with propositions as types.</li>
<div class="fragment">
<pre><code class="haskell">
half : (n : ℕ) → isEven n → ℕ
half .0 0even = 0
half .(succ (succ n)) (+2even n pf) = succ(half n pf)

</code></pre>
</div>
	  </ul>
	</section>

	<section>
	  <h3> A proof by induction </h3>
<div class="fragment">
<pre><code class="haskell">
double : ℕ → ℕ
double 0 = 0
double (succ n) = succ(succ(double(n)))

thm : (n  : ℕ) → isEven (double n)
thm zero = 0even
thm (succ n) = +2even _ (thm n)

</code></pre>
</div>

<div class="fragment">
<pre><code class="haskell">
halfOfDouble : ℕ → ℕ
halfOfDouble n = half (double n) (thm n)

</code></pre>
</div>
	</section>

	<section>
	  <h3> Some More types</h3>
<div class="fragment">
<pre><code class="haskell">
data True : Type where
  qed : True

data False : Type where

data _×_  (A B : Type) : Type where
  _,_ : A → B → A × B

data _⊕_  (A B : Type) : Type where
  ι₁ : A → A ⊕ B
  ι₂ : B → A ⊕ B

data Σ (A : Type) (B : A → Type) : Type where
  _,_ : (a : A) → (B a) → Σ A B

</code></pre>
</div>
	</section>

	<section>
	  <h3> Identity type family</h3>
	  <ul>
	    <li class="fragment"> For a fixed type $A$, propositional equality is given by the identity type family freely generated by reflexivity.</li>
<div class="fragment">
<pre><code class="haskell">
data _==_ {A : Type} : A → A → Type where
  refl : (a : A) → a == a
</code></pre>
</div>
	    <li class="fragment"> This is an inductive type family.</li>

<div class="fragment">
<pre><code class="haskell">
sym : {A : Type} → {x y : A} → (x == y) → (y == x)
sym (refl a) = refl a

_&&_ : {A : Type} → {x y z : A} → (x == y) → (y == z) → (x == z)
(refl a) && (refl .a) = refl a
</code></pre>
</div>

	    <li class="fragment"> However, for fixed $a: A$, $a = a$ is <strong> not </strong> an inductive type, i.e., it is not suffiicient to define functions on $refl(a)$.</li>
	  </ul>
	  </section>
</section>


<section>
	<section>
		<h3>Homotopy type theory: Types as Spaces</h3>
		<p> Equality and Paths </p>
		<p> $\infty$-groupoids from induction for equality</p>
		<p> Type families as fibrations </p>
		<p> Homotopy $n$-types (dimension)</p>
		<p> Classifying spaces and Univalence</p>
		<p> Synthetic homotopy theory</p>
	</section>

	<section>
	  <h3> Types as Spaces </h3>
	  <ul>
	    <li class="fragment"> We <em>interpret</em>
	      <ul>
		<li class="fragment"> Types as spaces. </li>
		<li class="fragment"> Terms of a type as points of the space.</li>
		<li class="fragment"> Functions $A \to B$ as continuous maps $A \to B$.
		<li class="fragment"> For a type $A$ and terms $x, y: A$, the identity type $x = y$ as paths in $A$ from $x$ to $y$.</li>
	      </ul></li>
	    <li class="fragment"> We do not actually construct spaces, i.e., sets with topology, starting with a type.</li>
	    <li class="fragment"> Instead we make topological (specifically homotopy theoretic) constructions and prove topological results in type theory.</li>
	    <li class="fragment"> A practical consequence for type theories is that we get a canonical type theory.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Paths, Products, Homotopy</h3>
	  <ul>
	    <li class="fragment"> As above, for a type $A$ and $x, y : A$, a term $p : (x = y)$ is interpreted as a path from $x$ to $y$.</li>
	    <li class="fragment"> We can invert such a path - this is just the symmetry function on identity types $(x = y) \to (y = x)$.</li>
	    <li class="fragment"> Similarly for $x, y, z: A$, the product of $p : x = y$ and $q : y = z$ is given by the <em>transitivity of equality</em> function $(x = y) \to (y = z)\to (x = z)$.</li>
	    <li class="fragment"> For $x, y, z : A$, given paths, $p : x = y$, $q : y = z$ and $r: z = w$, with $x, y, z, w : A$, we can prove that there is a path of paths, i.e., a homotopy, between $(p * q) * r$ and $p * (q * r)$. </li>
	    <li class="fragment"> Such a homotopy, which is constructed by induction, is just an element of $(p * q) * r = p * (q * r).$</li>
	  </section>

	<section>
	  <h3> Fundamental groupoids and $\infty$-groupoids </h3>
	  <ul>
	    <li class="fragment"> Thus, considering paths up to homotopy, we get the fundamental groupoid of a type.</li>
	    <li class="fragment"> We can instead consider the non-associative products on paths directly, together with a higher structure, namely a homotopy $(p * q) * r \sim p * (q * r)$ for paths $p$, $q$ and $r$ as above.</li>
	    <li class="fragment"> This process continues to give an $\infty$-groupoid structures on types, from the induction principle for identity type families.</li>
	    <li class="fragment"> The homotopy hypothesis says that $\infty$-groupoids are homotopy types of spaces.</li>
	    </ul>
	  </section>


	<section>
	  <h3> Associativity up to homotopy : the Pentagon </h3>
	  <img src="pentagon.svg" />
	</section>

	<section>
	  <h3> Loop spaces and homotopy groups </h3>
	  <ul>
	    <li class="fragment"> A based type is a type $A$ together with a term $a : A$.</li>
	    <li class="fragment"> We can associate to a based type $(A, a)$ its loop space, which is the based type $(a = a, refl(a))$.</li>
	    <li class="fragment"> We have a product on the loop space, using which we can define its fundamental group.</li>
	    <li class="fragment"> Further, iterating this process, we can define higher homotopy groups.</li>
	  </ul>
	</section>

	<section>
	  <h3> Type families as fibrations</h3>
	  <ul>
	    <li class="fragment"> We can show that any type family $P : A \to \mathfrak{U}$ is a <em> fibration</em>, i.e., we can lift paths and homotopies.</li>
	    <li class="fragment"> Using path lifting, given $x, y: A$ and an equality $p: x = y$, we can define a <em> transfer</em> function $p_* : P(x) \to P(y)$.</li>
	    <li class="fragment"> This allows us to transfer structure between equal objects, but depending on the choice of equality.</li>
	    <li class="fragment"> If $x, y: A$, $p: x = y$ and $f: \prod_{a : A} P(a)$ then $f(y) = p_*(f(x))$.</li>
	    <li class="fragment"> As a consequence of Voevodsky's univalence axiom, isomorphic types are equal, making the transfer very useful (but still consistent).</li>
	    <li class="fragment"> An axiom here is a term of a specified type, which we introduce. This has  no given properties other than its type.</li>
	  </section>

	<section>
	  <h3> Classifying spaces and Univalence </h3>
	  <ul>
	    <li class="fragment"> We can define when a function $f: A \to B$ is an equivalence of types, essentially like homotopy equivalence.</li>
	    <li class="fragment"> This lets us construct the type $A\simeq B$ of equivalences from $A$ to $B$.</li>
	    <li class="fragment"> There is a natural inclusion $A = B \to A \simeq B$.</li>
	    <li class="fragment"> Voevodsky's univalence axiom says that this is an equivalence.</li>
	    <li class="fragment"> This is the uniqueness part of universes being classifying spaces for types.</li>
	  </ul>
	  </section>


	<section>
	  <h3>Homotopy $n$-types </h3>
	  <ul>
	    <li class="fragment"> A homotopy $n$-type is the homotopy type of a space with trivial homotopy groups above dimension $n$.</li>
	    <li class="fragment"> We can define this inductively, with  the homotopy type of a space $X$ a homotopy $(n + 1)$-type if for $a, b : X$, the path space $\Omega(X; a, b)$ is a homotopy $n$-type.</li>
	    <li class="fragment"> We can start the induction with $n = -2$, where we require $X$ to be contractible (in particular non-empty).</li>
	    <li class="fragment"> This hierarchy gives definitions in type theory.</li>
	    <li class="fragment"> Further, we can truncate a type canonically to an $n$-type.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Sets and <strong>mere</strong> propositions </h3>
	  <ul>
	    <li class="fragment"> A set is a space with all of its components contractible.</li>
	    <li class="fragment"> A type $A$ is a set if for $x, y: A$ and $p, q: x = y$, we have $p = q$.</li>
	    <li class="fragment"> A mere proposition is a type which is either empty or all of its elements are equal.</li>
	    <li class="fragment"> Formally, $$isPropn(A) = \prod_{x : A} \prod_{y : A} (x = y).$$</li>
	    <li class="fragment"> The concept of mere propostions, as well as propositional truncation, allow consistent mixing of classical logic with the type theoretic form.</li>
	  </section>

	<section>
	  <h3> Higher inductive types </h3>
	  <p style="text-align:left"> In analogy with attaching cells of dimension $2$ and above, we can introduce (consistent) rules for introducing <em> higher inductive types</em>.
	  </section>

	<section>
	  <h3> Synthetic homotopy theory </h3>
	  <p style="text-align:left"> In the other direction, by axiomatizing type theoretic principles, we can develop <em>synthetic homotopy theory</em>, where the primitive concepts are spaces, points, maps, paths etc. but without requiring sets or topologies on them.</p>
</section>



		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom


				math: {
					mathjax: '../MathJax/MathJax.js',
					// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
					config: 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
				},

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../highlight/highlight.pack.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true}
				]
			});

//			Reveal.addEventListener( 'slidechanged', function( event ) {
//				MathJax.Hub.Rerender();
//			} );

		</script>

	</body>
</html>
