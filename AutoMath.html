<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Can computers conquer mathematics?</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/moon.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<link rel="icon" href="../IIScLogo.jpg">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<section>
	<h2> Can computers conquer mathematics? </h2>
	<h3> HoTT Foundations, Learning </h3>
	<h2>Siddhartha Gadgil</h2>
	 <p>Department of Mathematics</p>
	 <p>Indian Institute of Science</p>
	 <p>Bangalore</p>
	 <p><a href="https://github.com/siddhartha-gadgil/ProvingGround" target="_blank">https://github.com/siddhartha-gadgil/ProvingGround</a></p>

</section>

<section>
	<section>
		<h3>Theorem Proving:</h3>
		<h3> Enumeration, Computation, Deduction </h3>
		<p>Goals</p>
		<p>Computer-Assisted proof components</p>
		<p>Automated Deduction</p>
		<p> Limits of Set theory and First-order Logic</p>
	</section>
	<section>
		<h3> Goals </h3>
		<ul>
			<li><b> Goal:</b> Use computers to greatly increase our ability to discover and prove
				mathematical results across areas of mathematics.</li>
			<li class="fragment"> Why? </li>
			<li class="fragment"> How? </li>
		</section>
		<section>
			<h3> What? </h3>
			<ul>
				<li class="fragment"> There are infinitely many prime numbers. </li>
				<li class="fragment"> There are arbitrarily long arithmetic sequences all of whose elements are prime numbers. </li>
				<li class="fragment"> There are infinitely many natural numbers $n$ such $n$ and $n+2$ are both primes.</li>
			</ul>
		</section>
	<section>
		<h3> Computer-Assisted proof components </h3>
		<ul>
			<li class="fragment"> Computers have been used in various ways to provide a component of a proof:
				<ul>
					<li> Enumeration, </li>
					<li> Symbolic algebra, </li>
					<li> Exact real number arithmetic, </li>
					<li> Linear programming, </li>
					<li> SAT solvers.</li>
				</ul>
			</li>

			<li class="fragment"> Some examples:
				<ul>
					<li> Four colour theorem, </li>
					<li> Kepler conjecture, </li>
					<li> Boolean Pythagorean triples problem. </li>
				</ul>
			</li>
		</ul>

	</section>

	<section>
	  <h3> First-order logic: languages</h3>
	  <ul>
	  <li> A first-order language, which describes a domain of discourse (e.g. $\mathbb{N}) has vocabulary consisting of
	    <ul>
	      <li> Variables - can be taken to be a fixed countable set.</li>
	      <li> Constants (e.g. $0$, $1$).</li>
	      <li> Functions  (e.g. $+$).</li>
	      <li> Predicates (e.g. $<$, $=$).</li>
	      <li> Special symbols $\Rightarrow$, $\iff$, $\wedge$, $\vee$, $\forall$, $\exists$, ... </li>
	      </ul>
	    <li> We form two kinds of expressions from these, <em>terms</em> and <em> formulas </em>.</li>
	    <li> Terms and formulas may depend on values of some variables.</li>
	    <li> Terms represent objects in the <em> Universe</em>. </li>
	    <li> Formulas are either <em>true</em> or <em>false</em>. </li>
	    </ul>
	</section>

	<section>
	  <h3> Deduction and theories </h3>
	  <ul>
	    <li class="fragment"> We can deduce formulas from other formulas using the rules of deduction. </li>
	    <li class="fragment"> The main deduction rule is <em> Modus Ponens</em> : given $P$ and $P\Rightarrow Q$ we deduce $Q$.</li>
	    <li class="fragment"> A <em> theory</em> is a language together with a collection of statements, called <em> axioms</em> in the language.</li>
	    <li class="fragment"> A statement is <em> deducible</em> in a theory if it can be obtained from the axioms by the rules of deduction.</li>
	  </ul>
	</section>

	<section>
		<h3> Universal deducer? </h3>
		<ul>
			<li class ="fragment"> An ultimate prover is a function which, given a proposition which has a proof,
				returns such a sequence of deductions.</li>
			<li class="fragment"> By results of Turing, there is no such function. </li>
			<li class="fragment"> We can enumerate proofs and check if they prove either the given proposition or its negation.
				<span class="fragment"> This does not always work as there are statements that are true but not provable.</span>
			</li>
			 <li class="fragment"> Practically, we can conclude that there is no best deducer,
				 as all proofs can be found but no deducer can find them all. </li>
		</ul>
	</section>

	<section>
		<h3> Resolution theorem proving: Clausal normal form </h3>
		<ul>
			<li> To prove a proposition $P$ from axioms, we can derive a contradiction from $\neg P$ and the axioms.</li>
			<li> We can rewrite $\implies$ 
		</ul>
	</section>

	<section>
		<h3> Machine learning for first-order logic deducers</h3>
	</section>

	<section>
		<h3> Robbins conjecture </h3>
	</section>

	<section>
		<h3> Real-life mathematics</h3>
	</section>

	<section>
	  <p>
	    &ldquo; Since the first half of the 20th century mathematics has been presented as a science based on
	    ZFC and ZFC was introduced as a particular theory in Predicate Logic.
	  </p>
	  <p>
	    &ldquo; Therefore someone who wanted to get to the bottom of things in mathematics had a simple
	    road to follow - learn what Predicate Logic is, then learn a particular theory called ZFC, then
	    learn how to translate propositions about a few basic mathematical concepts into formulas of
	    ZFC, and then <span class="fragment highlight-red"> learn to believe, through examples, that the rest of mathematics can be reduced
	    to these few basic concepts</span>.&rdquo;</p>
<div style="text-align:right">Vladimir Voevodsky</div>
	  </section>

	<section>
		<h3> Why new foundations? </h3>
	</section>

	<section>
<p>
<q> &ldquo; The roadblock that prevented generations of interested mathematicians and computer scientists
from solving the problem of computer verification of mathematical reasoning was the
unpreparedness of foundations of mathematics for the requirements of this task.&rdquo;</q></p>
<p>
<q> &ldquo; Formulating mathematical reasoning in a language <span style="color:green">precise enough for a computer to follow</span>
meant using a foundational system of mathematics <span class="fragment highlight-blue"> not as a standard of consistency applied only
to establish a few fundamental theorems, but as a tool that can be employed in everyday
mathematical work.</span> &rdquo;</q></p>


<div style="float:right"> Vladimir Voevodsky</div>

	</section>

</section>


<section>
	<section>
		<h3> Martin-L&Oumlf Type theory</h3>
			<p> Type theoretic Foundations</p>
		 	<p>Terms, Types, Rules</p>
		 	<p>Inductive types</p>
		 	<p> Dependent Types</p>
		 	<p>Propositions as types</p>
	</section>
	<section>
		<h3> Type theoretic foundations</h3>
		<ul>
			<li class="fragment"> Mathematical objects, called <em class="fragment highlight-current-blue"> terms</em> have <em class="fragment highlight-current-blue"> types </em>. </li>
			<li class="fragment"> A term $a$ having a type $A$, denoted $a : A$, is analogous to
				an element $a$ belonging to a set $A$, i.e., $a \in A$.</li>
			<li class="fragment"> However the rules for forming terms and types, and for determining
				whether a term has a type, are purely <em class="fragment highlight-current-blue"> syntactic. </em></li>
			<li class="fragment"> Nevertheless, the rules for forming types are rich enough that types can play the role of sets
				<span class="fragment"> - for instance, prime numbers form a type.</span>
			 </li>
			<li class="fragment"> Even more remarkably, propositions and proofs can be expressed in terms of types and terms.
			</li>
		</ul>
	</section>

	<section>
	  <h3> Terms, Types, Rules </h3>
	  <ul>
	  <li class="fragment"> Mathematical objects are called <em class="fragment highlight-current-blue">terms. </em> </li>
	  <li  class="fragment"> Every term has a <em class="fragment highlight-current-blue"> type </em>, generally unique.</li>
	  <li class="fragment"> Types are also terms, whose types are <em class="fragment highlight-current-blue"> universes</em>.</li>
		<li class="fragment"> We have <em class="fragment highlight-current-blue">rules</em> to introduce terms (including types), individually or in groups, into the context.</li>
		<li class="fragment"> Rules also let us make two kinds of <strong>judgements</strong>:
	  	<ul>
				<li> that a term $a$  is of type $A$. </li>
				<li> that two terms are equal <em class="fragment highlight-current-blue"> by definition </em>.
				</ul>
			</li>
			<li class="fragment"> All the rules are syntactic.</em>
	    <li class="fragment">  Note that terms can be equal without being so by definition. </li>
	    <li class="fragment"> There is a relation (type family) <em class="fragment highlight-current-blue"> propositional equality</em> extending definitional equality.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Function types, functions and applications </h3>
	  <ul>
	    <li class="fragment"> Given types $A$ and $B$, we can introduce the function type $A \to B$, whose members are functions.</li>
	    <li class="fragment"> Given $f: A \to B$ and $a : A$, we get a term $f(a) : B$.</li>
	    <div class="fragment">
	      <li> We can construct a function $f: A \to B$ by giving an expression $b$ of type $B$
					in terms of a variable $a : A$ and other terms in the context, i.e., $f : a \mapsto b$.</li>
</div>
	    <li class="fragment"> We can also define functions <em class="fragment highlight-current-blue"> recursively</em> on <em class="fragment highlight-current-blue"> inductive types </em>.</li>
	    </ul>
	</section>


	<section>
	  <h3>  Inductive types</h3>
	  <ul>
			<li class="fragment"> An inductive type $T$
				 is defined by specifying terms (usually functions)
				that construct members of $T$. </li>

<pre class="fragment"><code class="haskell">
data ℕ : Type where
  zero : ℕ
  succ : ℕ → ℕ
</code></pre>
<pre class="fragment"><code class="scala">
sealed class Nat
case object zero extends Nat
case class succ(n: Nat) extends Nat
</code></pre>
	<li class="fragment"> Formally, we are introducing into the context the type $\mathbb{N}$ and two terms $0$ and $succ$.</li>
	<li class="fragment"> The type is <em class="fragment highlight-current-blue"> freely generated</em> by its constructors, allowing recursive
		and inductive definitions.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Recursive definitions </h3>
	  <ul>
	    <li class="fragment"> We can define functions recursively on inductive types, by specifying in all cases.</li>

<div>
<pre class="fragment"><code class="haskell">
_+_ : ℕ → ℕ → ℕ
zero + y = y
(succ x) + y = succ (x + y)
	</code></pre>
<pre class="fragment"><code class="scala">
val sum: Nat => Nat => Nat = {
	  case zero => (m: Nat) => m
	  case succ(n) => (m: Nat) => succ(sum(n)(m))
	}
</code></pre>
</div>
<li class="fragment"> Formally, we can introduce recursion functions and apply them to the definition data. </li>
</ul>
	</section>


	<section>
	  <h3> Dependent functions and type families </h3>
	  <ul>
	    <li class="fragment"> We generalize functions $f : A \to B$ to <em class="fragment highlight-current-blue"> dependent functions</em>, so that $f(a)$ has a type $B(a)$, depending in general on $a : A$.</li>
	    <li class="fragment"> More precisely,
	      <ul>
		<li class="fragment"> A <em class="fragment highlight-current-blue"> type family</em> $B: A \to \mathfrak{U}$ is a function with codomain a universe, so all its values are types. </li>
		<li class="fragment"> Given a type family $B: A \to \mathfrak{U}$, we can construct a corresponding type $\prod_{a : A} B(a)$ of dependent functions.</li>
		<li class="fragment"> When we apply $f : \prod_{a : A} B(a)$ to $a : A$, we obtain $f(a) : B(a)$.</li>
		</ul>
	      </li>
	  <li class="fragment"> Constructions of dependent functions are analogous to those of functions.</li>
	  </ul>
	  </section>

	<section>
	  <h3>Vectors : an inductive type family </h3>
	  <ul>
	    <li class="fragment"> We have a type family associating to each $n : \mathbb{N}$ the type of vectors of length $n$ with entries in $\mathbb{N}$.</li>
	    <li class="fragment"> This is an inductive type family with two constructors.</li>
<div class="fragment">
<pre><code class="haskell">
data Vector (A : Type) : ℕ → Type where -- inductive type family
  [] : Vector A 0
  _::_ : {n : ℕ} → A → Vector n → Vector (succ n)
</code></pre>
</div>
	    <li class="fragment"> We can define dependent functions to this type family <em class="fragment highlight-current-blue">inductively</em>.</li>
<div class="fragment">
<pre><code class="haskell">
countdown : (n : ℕ) → Vector ℕ n -- dependent function
countdown 0 = []
countdown (succ n) = (succ n) :: (countdown n)
</code></pre>
</div>
	    <li class="fragment"> Formally, we can construct an <em class="fragment highlight-current-blue">induction function</em> and apply it to the data.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Functions on type families </h3>
	  <ul>
	    <li class="fragment"> We can define (dependent) functions on inductive type families recursively (inductively).</li>
	    <li class="fragment"> However, we must define these simultaneously on all types in the inductive type family.</li>
<div class="fragment">
<pre><code class="haskell">
sum : {n : ℕ} → Vector ℕ n → ℕ
sum [] = 0
sum (x :: l) = x + sum l
</code></pre>
</div>
	  </ul>
	  </section>

		<section>
			<h3> Some useful Inductive types</h3>
			<ul>
				<li>
			We can inductively define the types $\mathbb{0}$, $\mathbb{1}$, $A \times B$, $A \oplus B$.</li>
			<li> For a type family $B: A \to \mathcal{U}$, the <em class="fragment highlight-current-blue">dependent pair</em> type $\Sigma$
				has terms pairs $(a, b)$ with $b : B(a)$</li>
	<div class="fragment">
	<pre><code class="haskell">
	data True : Type where
		qed : True

	data False : Type where

	data _×_  (A B : Type) : Type where
		_,_ : A → B → A × B

	data _⊕_  (A B : Type) : Type where
		ι₁ : A → A ⊕ B
		ι₂ : B → A ⊕ B

	data Σ (A : Type) (B : A → Type) : Type where
		_,_ : (a : A) → (B a) → Σ A B
	</code></pre>
	</div>
		</section>


		<section>
			<h3>Propositions as types</h3>
			<ul>
				<li class="fragment">A type $A$ is <em class="fragment highlight-current-blue">inhabited</em> if there is a term $a$ with $a : A$.</li>
				<li class="fragment">By <em class="fragment highlight-current-blue"> propostion</em> we mean a logical statement that must be true or false.</li>
				<li class="fragment">We represent propositions by types.</li>
				<li class="fragment">If a type $A$ is viewed as a proposition, a term $a : A$ is a <em class="fragment highlight-current-blue">proof</em> of (or witness to) $A$.
				<li class="fragment">In particular, a proposition is <strong>true</strong> if and only if the corresponding type is <strong>inhabited</strong>.</li>
				<li class="fragment">Note that we must be able to form types representing propositions of interest in mathematics by the type formation rules.</li>
			</ul>
		</section>

		<section>
			<h3>Combining propositions</h3>
			<p class="fragment"> Let $A$ and $B$ be types, regarded as representing propositions.</p>
			<ul>
				<li class="fragment"> The proposition $A \Rightarrow B$ is represented by $A \to B$.</li>
				<li class="fragment"> The propostion $A\wedge B$ is represented by $A \times B$.</li>
				<li class="fragment"> The proposition $A \vee B$ is represented by $A \oplus B$.</li>
				<li class="fragment"> The proposition $\neg A$ is represented by $A \to \mathbb{0}$.</li>
			</ul>
		</section>

		<section>
			<h3>Quantifying propositions</h3>
			<ul>
				<li class="fragment">A proposition depending on a variable $x : A$ is represented by a type family $P : A \to \mathfrak{U}$. </li>
				<li class="fragment">The proposition $\forall x\ P(x)$ is represented by $\prod_{x: A} P(x)$.</li>
				<li class="fragment">The proposition $\exists x\ P(x)$ is represented by $\sum_{x : A} P(x)$.</li>
			</ul>
		</section>

	<section>
	  <h3> Identity type family</h3>
	  <ul>
	    <li class="fragment"> For a fixed type $A$, propositional equality is given by the identity type family freely generated by reflexivity.</li>
<div class="fragment">
<pre><code class="haskell">
data _==_ {A : Type} : A → A → Type where
  refl : (a : A) → a == a
</code></pre>
</div>
	    <li class="fragment"> This is an inductive type family.</li>

<div class="fragment">
<pre><code class="haskell">
symmetry : {A : Type} → {x y : A} → (x == y) → (y == x)
symmetry (refl a) = refl a

trans : {A : Type} → {x y z : A} → (x == y) → (y == z) → (x == z)
trans (refl a) (refl .a) = refl a
</code></pre>
</div>
	    <li class="fragment"> However, for fixed $a: A$, $a = a$ is <strong> not </strong> an inductive type, i.e., it is not suffiicient to define functions on $refl(a)$.</li>
	  </ul>
	  </section>
</section>


<section>
	<section>
		<h3>Homotopy type theory: Types as Spaces</h3>
		<p> Equality and Paths </p>
		<p> $\infty$-groupoids from induction for equality</p>
		<p> Type families as fibrations </p>
		<p> Homotopy $n$-types (dimension)</p>
		<p> Classifying spaces and Univalence</p>
		<p> Synthetic homotopy theory</p>
	</section>

	<section>
	  <h3> Types as Spaces </h3>
	  <ul>
	    <li class="fragment"> We <em class="fragment highlight-current-blue">interpret</em>
	      <ul>
		<li class="fragment"> Types as spaces. </li>
		<li class="fragment"> Terms of a type as points of the space.</li>
		<li class="fragment"> Functions $A \to B$ as continuous maps $A \to B$.
		<li class="fragment"> For a type $A$ and terms $x, y: A$, the identity type $x = y$ as paths in $A$ from $x$ to $y$.</li>
	      </ul></li>
	    <li class="fragment"> We do not actually construct spaces, i.e., sets with topology, starting with a type.</li>
	    <li class="fragment"> Instead we make topological (specifically homotopy theoretic) constructions and prove topological results in type theory.</li>
	    <li class="fragment"> A practical consequence for type theories is that we get a canonical type theory.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Paths, Products, Homotopy</h3>
	  <ul>
	    <li class="fragment"> As above, for a type $A$ and $x, y : A$, a term $p : (x = y)$ is interpreted as a path from $x$ to $y$.</li>
			<img src="HomotopySmall.gif" class="fragment"/>
			<img src="Mug_and_Torus_morph.gif" class="fragment" />
	    <li class="fragment"> We can invert such a path - this is just the symmetry function on identity types $(x = y) \to (y = x)$.</li>
	    <li class="fragment"> Similarly for $x, y, z: A$, the product of $p : x = y$ and $q : y = z$ is given by the <em class="fragment highlight-current-blue">transitivity of equality</em> function $(x = y) \to (y = z)\to (x = z)$.</li>
	    <li class="fragment"> For $x, y, z : A$, given paths, $p : x = y$, $q : y = z$ and $r: z = w$, with $x, y, z, w : A$, we can prove that there is a path of paths, i.e., a homotopy, between $(p * q) * r$ and $p * (q * r)$. </li>
	    <li class="fragment"> Such a homotopy, which is constructed by induction, is just an element of $(p * q) * r = p * (q * r).$</li>
	  </section>

	<section>
	  <h3> Fundamental groupoids and $\infty$-groupoids </h3>
	  <ul>
	    <li class="fragment"> Thus, considering paths up to homotopy, we get the fundamental groupoid of a type.</li>
	    <li class="fragment"> We can instead consider the non-associative products on paths directly, together with a higher structure, namely a homotopy $(p * q) * r \sim p * (q * r)$ for paths $p$, $q$ and $r$ as above.</li>
	    <li class="fragment"> This process continues to give an $\infty$-groupoid structures on types, from the induction principle for identity type families.</li>
	    <li class="fragment"> The homotopy hypothesis says that $\infty$-groupoids are homotopy types of spaces.</li>
	    </ul>
	  </section>


	<section>
	  <h3> Associativity up to homotopy : the Pentagon </h3>
	  <img src="pentagon.svg" />
	</section>

	<section>
	  <h3> Loop spaces and homotopy groups </h3>
	  <ul>
	    <li class="fragment"> A based type is a type $A$ together with a term $a : A$.</li>
	    <li class="fragment"> We can associate to a based type $(A, a)$ its loop space, which is the based type $(a = a, refl(a))$.</li>
	    <li class="fragment"> We have a product on the loop space, using which we can define its fundamental group.</li>
	    <li class="fragment"> Further, iterating this process, we can define higher homotopy groups.</li>
	  </ul>
	</section>

	<section>
	  <h3> Type families as fibrations</h3>
	  <ul>
	    <li class="fragment"> We can show that any type family $P : A \to \mathfrak{U}$ is a <em class="fragment highlight-current-blue"> fibration</em>, i.e., we can lift paths and homotopies.</li>
	    <li class="fragment"> Using path lifting, given $x, y: A$ and an equality $p: x = y$, we can define a <em class="fragment highlight-current-blue"> transfer</em> function $p_* : P(x) \to P(y)$.</li>
	    <li class="fragment"> This allows us to transfer structure between equal objects, but depending on the choice of equality.</li>
	    <li class="fragment"> If $x, y: A$, $p: x = y$ and $f: \prod_{a : A} P(a)$ then $f(y) = p_*(f(x))$.</li>
	    <li class="fragment"> As a consequence of Voevodsky's univalence axiom, isomorphic types are equal, making the transfer very useful (but still consistent).</li>
	    <li class="fragment"> An axiom here is a term of a specified type, which we introduce. This has  no given properties other than its type.</li>
	  </section>

	<section>
	  <h3> Classifying spaces and Univalence </h3>
	  <ul>
	    <li class="fragment"> We can define when a function $f: A \to B$ is an equivalence of types, essentially like homotopy equivalence.</li>
	    <li class="fragment"> This lets us construct the type $A\simeq B$ of equivalences from $A$ to $B$.</li>
	    <li class="fragment"> There is a natural inclusion $A = B \to A \simeq B$.</li>
	    <li class="fragment"> Voevodsky's univalence axiom says that this is an equivalence.</li>
	    <li class="fragment"> This is the uniqueness part of universes being classifying spaces for types.</li>
	  </ul>
	  </section>


	<section>
	  <h3>Homotopy $n$-types </h3>
	  <ul>
	    <li class="fragment"> A homotopy $n$-type is the homotopy type of a space with trivial homotopy groups above dimension $n$.</li>
	    <li class="fragment"> We can define this inductively, with  the homotopy type of a space $X$ a homotopy $(n + 1)$-type if for $a, b : X$, the path space $\Omega(X; a, b)$ is a homotopy $n$-type.</li>
	    <li class="fragment"> We can start the induction with $n = -2$, where we require $X$ to be contractible (in particular non-empty).</li>
	    <li class="fragment"> This hierarchy gives definitions in type theory.</li>
	    <li class="fragment"> Further, we can truncate a type canonically to an $n$-type.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Sets and <strong>mere</strong> propositions </h3>
	  <ul>
	    <li class="fragment"> A set is a space with all of its components contractible.</li>
	    <li class="fragment"> A type $A$ is a set if for $x, y: A$ and $p, q: x = y$, we have $p = q$.</li>
	    <li class="fragment"> A mere proposition is a type which is either empty or all of its elements are equal.</li>
	    <li class="fragment"> Formally, $$isPropn(A) = \prod_{x : A} \prod_{y : A} (x = y).$$</li>
	    <li class="fragment"> The concept of mere propostions, as well as propositional truncation, allow consistent mixing of classical logic with the type theoretic form.</li>
	  </section>

	<section>
	  <h3> Higher inductive types </h3>
	  <p style="text-align:left"> In analogy with attaching cells of dimension $2$ and above, we can introduce (consistent) rules for introducing <em class="fragment highlight-current-blue"> higher inductive types</em>.
	  </section>

	<section>
	  <h3> Synthetic homotopy theory </h3>
	  <p style="text-align:left"> In the other direction, by axiomatizing type theoretic principles, we can develop <em class="fragment highlight-current-blue">synthetic homotopy theory</em>, where the primitive concepts are spaces, points, maps, paths etc. but without requiring sets or topologies on them.</p>
	</section>


</section>

<section>
	<section>
		<h3> Proving-Ground: Theorem proving by Learning</h3>
	</section>
</section>



		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom


				math: {
					mathjax: '../MathJax/MathJax.js',
					// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
					config: 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
				},

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../highlight/highlight.pack.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true}
				]
			});

//			Reveal.addEventListener( 'slidechanged', function( event ) {
//				MathJax.Hub.Rerender();
//			} );

		</script>

	</body>
</html>
